{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install openai pandas openpyxl tqdm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 271/271 [50:19<00:00, 11.14s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\ë¡¯ë°ì¹´ë“œ_ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>gpt_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VaBG145v0UM</td>\n",
       "      <td>@newskbs</td>\n",
       "      <td>0:19 ìë§‰ì— 297ë§Œ ì—¬ëª…ì„ 2ì²œ 97ë§Œ ì—¬ëª…ìœ¼ë¡œ ì˜ëª» í‘œê¸°í–ˆìŠµë‹ˆë‹¤. ì´ìš©ì— ë¶ˆ...</td>\n",
       "      <td>2025-09-21T02:21:37Z</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VaBG145v0UM</td>\n",
       "      <td>@ë¶€ì •ì„ ê±°out</td>\n",
       "      <td>ì „ì„¸ê³„ì˜ ì•… ã…¡ì´ìŠ¬ëŒ ì¤‘êµ­</td>\n",
       "      <td>2025-10-23T13:06:36Z</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VaBG145v0UM</td>\n",
       "      <td>@ë³´ë…¸_ë³´ë”</td>\n",
       "      <td>ì•„ì§ìœ¼ìœ¼ìœ¼ì‘ìœ¼ì€?</td>\n",
       "      <td>2025-09-27T13:33:33Z</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VaBG145v0UM</td>\n",
       "      <td>@Ralph.C-h3r</td>\n",
       "      <td>ê»Œì´ë‚˜ ã…Š ã…•ë§Œë“¤ì–´ê°€ ì£ ë–¼ì•¼</td>\n",
       "      <td>2025-09-27T02:12:52Z</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VaBG145v0UM</td>\n",
       "      <td>@hejin_9158</td>\n",
       "      <td>ì§€ê¸ˆì€ ì—¬ê¸°ì €ê¸°ì„œ ë– ë“œë‹ˆê¹Œ í•´ì»¤ë“¤ì´ ê°€ì ¸ê°„ ì •ë³´ëŠ” ì¡°ìš©íˆ ìˆê² ì§€ë§Œ ì‚¬ê·¸ëŸ¬ë“¤ê³  ì¡°ìš©í•´...</td>\n",
       "      <td>2025-09-26T15:27:55Z</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId        author  \\\n",
       "0  VaBG145v0UM      @newskbs   \n",
       "1  VaBG145v0UM      @ë¶€ì •ì„ ê±°out   \n",
       "2  VaBG145v0UM        @ë³´ë…¸_ë³´ë”   \n",
       "3  VaBG145v0UM  @Ralph.C-h3r   \n",
       "4  VaBG145v0UM   @hejin_9158   \n",
       "\n",
       "                                                text           publishedAt  \\\n",
       "0  0:19 ìë§‰ì— 297ë§Œ ì—¬ëª…ì„ 2ì²œ 97ë§Œ ì—¬ëª…ìœ¼ë¡œ ì˜ëª» í‘œê¸°í–ˆìŠµë‹ˆë‹¤. ì´ìš©ì— ë¶ˆ...  2025-09-21T02:21:37Z   \n",
       "1                                     ì „ì„¸ê³„ì˜ ì•… ã…¡ì´ìŠ¬ëŒ ì¤‘êµ­  2025-10-23T13:06:36Z   \n",
       "2                                          ì•„ì§ìœ¼ìœ¼ìœ¼ì‘ìœ¼ì€?  2025-09-27T13:33:33Z   \n",
       "3                                    ê»Œì´ë‚˜ ã…Š ã…•ë§Œë“¤ì–´ê°€ ì£ ë–¼ì•¼  2025-09-27T02:12:52Z   \n",
       "4  ì§€ê¸ˆì€ ì—¬ê¸°ì €ê¸°ì„œ ë– ë“œë‹ˆê¹Œ í•´ì»¤ë“¤ì´ ê°€ì ¸ê°„ ì •ë³´ëŠ” ì¡°ìš©íˆ ìˆê² ì§€ë§Œ ì‚¬ê·¸ëŸ¬ë“¤ê³  ì¡°ìš©í•´...  2025-09-26T15:27:55Z   \n",
       "\n",
       "  gpt_sentiment  gpt_confidence  \n",
       "0            ë¶€ì •            0.85  \n",
       "1            ë¶€ì •            0.90  \n",
       "2            ì¤‘ë¦½            0.50  \n",
       "3            ì¤‘ë¦½            0.55  \n",
       "4            ì¤‘ë¦½            0.50  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê°ì •ë¶„ì„ ì´ˆê³ ì† ì•ˆì • ë²„ì „ (Batch + JSON ì¶œë ¥ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"GPT ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥ë“¤ì˜ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì •í™•íˆ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼ ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # âš¡ ì´ˆê³ ì† ëª¨ë¸\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬ ì¶”ê°€)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------------\n",
    "input_paths = [\n",
    "    r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\ë¡¯ë°ì¹´ë“œ_ì •ë³´ìœ ì¶œ_comments_20251103_165555.xlsx\",\n",
    "    # r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\SKT_ìœ ì‹¬ì¹©_ìœ ì¶œ_comments_20251103_165204.xlsx\",\n",
    "    # r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\KT_í¨í† ì…€_í•´í‚¹_comments_20251103_152106.xlsx\"\n",
    "]\n",
    "\n",
    "dfs = [pd.read_excel(path) for path in input_paths]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "if \"text\" not in df.columns:\n",
    "    raise ValueError(\"âš ï¸ ì…ë ¥ íŒŒì¼ì— 'text' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip().str[:300]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"text\"].tolist(), batch_size=20)\n",
    "\n",
    "df[\"gpt_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ (ì—‘ì…€)\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\ë¡¯ë°ì¹´ë“œ__ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "# ìƒìœ„ 5í–‰ ë¯¸ë¦¬ë³´ê¸°\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 364/364 [1:04:12<00:00, 10.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\SKT_ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>gpt_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3B6nv74tSkw</td>\n",
       "      <td>@baramdori7</td>\n",
       "      <td>ë¯¸êµ­ì— ì§“ëŠ” ê³µì¥ë„ ë‹¤ ì¤‘ë‹¨í•˜ê³  ê·¸ê°„ ë“¤ì–´ê°„ ëˆì€ ë²„ë ¸ë‹¤ ìƒê°í•˜ëŠ”ê²Œ ì´ë“ì´ë‹¤. \\n...</td>\n",
       "      <td>2025-10-11T10:35:14Z</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3B6nv74tSkw</td>\n",
       "      <td>@berrycherry6558</td>\n",
       "      <td>í†µì‹ ì‚¬ ì•±ì´ë¼ëŠ”ê²Œ SKí…”ë ˆì½¤ì´ë©´ SKí…”ë ˆì½¤ ì•±ì„ ê¹”ì•„ì•¼ í•˜ëŠ”ê±´ê°€ìš”?</td>\n",
       "      <td>2025-10-02T01:47:26Z</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3B6nv74tSkw</td>\n",
       "      <td>@ì´ì •ë€-g4r</td>\n",
       "      <td>KTì•±ì—ì„œ ì •ë³´ë³´í˜¸ ì•Œë¦¼ì´ ì•ˆëœ¨ëŠ”ë°ìš”?</td>\n",
       "      <td>2025-09-27T02:06:02Z</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3B6nv74tSkw</td>\n",
       "      <td>@ë³´ë¼-j1w</td>\n",
       "      <td>íšŒì‚¬ ì§ì›ë¶„ì´ ë³´ì´ìŠ¤í”¼ì‹± ì „í™”ì˜¤ì…”ì„œ ëŒ€ì²˜ í›„ ì´ ì˜ìƒ ë³´ì—¬ë“œë¦¬ê³  ë”°ë¼í•˜ì…¨ìŠµë‹ˆë‹¤ ì¢‹ì€...</td>\n",
       "      <td>2025-09-26T03:07:35Z</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3B6nv74tSkw</td>\n",
       "      <td>@ì•„ë¦„ë“œë¦¬-q5e</td>\n",
       "      <td>ê°ì‚¬í•©ë‹ˆë‹¤.</td>\n",
       "      <td>2025-09-22T04:45:44Z</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId            author  \\\n",
       "0  3B6nv74tSkw       @baramdori7   \n",
       "1  3B6nv74tSkw  @berrycherry6558   \n",
       "2  3B6nv74tSkw          @ì´ì •ë€-g4r   \n",
       "3  3B6nv74tSkw           @ë³´ë¼-j1w   \n",
       "4  3B6nv74tSkw         @ì•„ë¦„ë“œë¦¬-q5e   \n",
       "\n",
       "                                                text           publishedAt  \\\n",
       "0  ë¯¸êµ­ì— ì§“ëŠ” ê³µì¥ë„ ë‹¤ ì¤‘ë‹¨í•˜ê³  ê·¸ê°„ ë“¤ì–´ê°„ ëˆì€ ë²„ë ¸ë‹¤ ìƒê°í•˜ëŠ”ê²Œ ì´ë“ì´ë‹¤. \\n...  2025-10-11T10:35:14Z   \n",
       "1              í†µì‹ ì‚¬ ì•±ì´ë¼ëŠ”ê²Œ SKí…”ë ˆì½¤ì´ë©´ SKí…”ë ˆì½¤ ì•±ì„ ê¹”ì•„ì•¼ í•˜ëŠ”ê±´ê°€ìš”?  2025-10-02T01:47:26Z   \n",
       "2                              KTì•±ì—ì„œ ì •ë³´ë³´í˜¸ ì•Œë¦¼ì´ ì•ˆëœ¨ëŠ”ë°ìš”?  2025-09-27T02:06:02Z   \n",
       "3  íšŒì‚¬ ì§ì›ë¶„ì´ ë³´ì´ìŠ¤í”¼ì‹± ì „í™”ì˜¤ì…”ì„œ ëŒ€ì²˜ í›„ ì´ ì˜ìƒ ë³´ì—¬ë“œë¦¬ê³  ë”°ë¼í•˜ì…¨ìŠµë‹ˆë‹¤ ì¢‹ì€...  2025-09-26T03:07:35Z   \n",
       "4                                             ê°ì‚¬í•©ë‹ˆë‹¤.  2025-09-22T04:45:44Z   \n",
       "\n",
       "  gpt_sentiment  gpt_confidence  \n",
       "0            ë¶€ì •            0.95  \n",
       "1            ì¤‘ë¦½            0.60  \n",
       "2            ì¤‘ë¦½            0.55  \n",
       "3            ì¤‘ë¦½            0.50  \n",
       "4            ê¸ì •            0.90  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê°ì •ë¶„ì„ ì´ˆê³ ì† ì•ˆì • ë²„ì „ (Batch + JSON ì¶œë ¥ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"GPT ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥ë“¤ì˜ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì •í™•íˆ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼ ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # âš¡ ì´ˆê³ ì† ëª¨ë¸\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬ ì¶”ê°€)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------------\n",
    "input_paths = [\n",
    "    r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\SKT_ìœ ì‹¬ì¹©_ìœ ì¶œ_comments_20251103_165204.xlsx\",\n",
    "    # r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\SKT_ìœ ì‹¬ì¹©_ìœ ì¶œ_comments_20251103_165204.xlsx\",\n",
    "    # r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\KT_í¨í† ì…€_í•´í‚¹_comments_20251103_152106.xlsx\"\n",
    "]\n",
    "\n",
    "dfs = [pd.read_excel(path) for path in input_paths]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "if \"text\" not in df.columns:\n",
    "    raise ValueError(\"âš ï¸ ì…ë ¥ íŒŒì¼ì— 'text' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip().str[:300]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"text\"].tolist(), batch_size=20)\n",
    "\n",
    "df[\"gpt_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ (ì—‘ì…€)\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\SKT_ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "# ìƒìœ„ 5í–‰ ë¯¸ë¦¬ë³´ê¸°\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ê²Œì‹œê¸€ ìˆ˜: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“Š GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\GS_posts_GPT_labeled.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>channelId</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>url</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>subscriberCount</th>\n",
       "      <th>text_raw</th>\n",
       "      <th>gpt_post_sentiment</th>\n",
       "      <th>gpt_post_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9GukLzTRkkM</td>\n",
       "      <td>ì£¼ì†Œì— í†µê´€ë²ˆí˜¸ê¹Œì§€â€¦GSë¦¬í…Œì¼, 158ë§Œëª… ì •ë³´ ìœ ì¶œ í™•ì¸ / JTBC ë‰´ìŠ¤ë£¸</td>\n",
       "      <td>ì§€ë‚œë‹¬ GSë¦¬í…Œì¼ì—ì„œë„ 9ë§Œ ëª…ì˜ ê°œì¸ì •ë³´ê°€ ìœ ì¶œë˜ëŠ” ì‚¬ê±´ì´ ë²Œì–´ì¡ŒìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ...</td>\n",
       "      <td>JTBC News</td>\n",
       "      <td>UCsU-I-vHLiaMfV_ceaYz5rQ</td>\n",
       "      <td>2025-02-27T11:45:38Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=9GukLzTRkkM</td>\n",
       "      <td>13151</td>\n",
       "      <td>228</td>\n",
       "      <td>120</td>\n",
       "      <td>4750000</td>\n",
       "      <td>ì£¼ì†Œì— í†µê´€ë²ˆí˜¸ê¹Œì§€â€¦GSë¦¬í…Œì¼, 158ë§Œëª… ì •ë³´ ìœ ì¶œ í™•ì¸ / JTBC ë‰´ìŠ¤ë£¸ ì§€ë‚œ...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qcQjIfuls3c</td>\n",
       "      <td>GSë¦¬í…Œì¼ ê³ ê° ì •ë³´ 9ë§Œì—¬ ê±´ í•´í‚¹ í”¼í•´â€¦3ì¼ ë§Œì— ì•Œë ¸ë‹¤ / SBS / #Dë¦¬í¬íŠ¸</td>\n",
       "      <td>GSë¦¬í…Œì¼ì´ ê³ ê°ë“¤ì—ê²Œ ì˜¤ëŠ˜(6ì¼) ì˜¤í›„ ë°œì†¡í•œ í•´í‚¹ í”¼í•´ ê³µì§€ ë¬¸ì¡ë‹ˆë‹¤. ì§€ë‚œë‹¬ ...</td>\n",
       "      <td>SBS ë‰´ìŠ¤</td>\n",
       "      <td>UCkinYTS9IHqOEwR1Sze2JTw</td>\n",
       "      <td>2025-01-06T09:57:34Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=qcQjIfuls3c</td>\n",
       "      <td>6297</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>5080000</td>\n",
       "      <td>GSë¦¬í…Œì¼ ê³ ê° ì •ë³´ 9ë§Œì—¬ ê±´ í•´í‚¹ í”¼í•´â€¦3ì¼ ë§Œì— ì•Œë ¸ë‹¤ / SBS / #Dë¦¬í¬...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ghSztNUxjB8</td>\n",
       "      <td>GSë¦¬í…Œì¼ ê³ ê° 9ë§Œ ëª… ê°œì¸ì •ë³´ ìœ ì¶œâ€¦í•´í‚¹ ê³µê²© / SBS 8ë‰´ìŠ¤</td>\n",
       "      <td>GSë¦¬í…Œì¼ì´ ì§€ë‚œë‹¬ 27ì¼ë¶€í„° ì´ë‹¬ 4ì¼ ì‚¬ì´ ì›¹ì‚¬ì´íŠ¸ í•´í‚¹ ê³µê²©ì„ ë°›ì•„ ê³ ê° 9ë§Œ...</td>\n",
       "      <td>SBS ë‰´ìŠ¤</td>\n",
       "      <td>UCkinYTS9IHqOEwR1Sze2JTw</td>\n",
       "      <td>2025-01-06T12:38:57Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=ghSztNUxjB8</td>\n",
       "      <td>4276</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>5080000</td>\n",
       "      <td>GSë¦¬í…Œì¼ ê³ ê° 9ë§Œ ëª… ê°œì¸ì •ë³´ ìœ ì¶œâ€¦í•´í‚¹ ê³µê²© / SBS 8ë‰´ìŠ¤ GSë¦¬í…Œì¼ì´ ì§€...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dAGkZUtGJ7Y</td>\n",
       "      <td>GSë¦¬í…Œì¼, í¸ì˜ì ì— í™ˆì‡¼í•‘ë„ í•´í‚¹â€¥158ë§Œ ê±´ ì¶”ê°€ ìœ ì¶œ (2025.02.27/ë‰´...</td>\n",
       "      <td>ì§€ë‚œë‹¬ í¸ì˜ì  í™ˆí˜ì´ì§€ì—ì„œ 9ë§Œì—¬ ëª…ì˜ ê°œì¸ì •ë³´ê°€ ìœ ì¶œëœ GSë¦¬í…Œì¼ì´ í™ˆì‡¼í•‘ ì›¹ì‚¬ì´...</td>\n",
       "      <td>MBCNEWS</td>\n",
       "      <td>UCF4Wxdo3inmxP-Y59wXDsFw</td>\n",
       "      <td>2025-02-27T06:24:05Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=dAGkZUtGJ7Y</td>\n",
       "      <td>3362</td>\n",
       "      <td>65</td>\n",
       "      <td>16</td>\n",
       "      <td>6040000</td>\n",
       "      <td>GSë¦¬í…Œì¼, í¸ì˜ì ì— í™ˆì‡¼í•‘ë„ í•´í‚¹â€¥158ë§Œ ê±´ ì¶”ê°€ ìœ ì¶œ (2025.02.27/ë‰´...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UwvL4geTjuA</td>\n",
       "      <td>GSë¦¬í…Œì¼ ê³ ê° 9ë§Œëª… í•´í‚¹..&amp;#39;ê²¨ìš¸ë³„ë¯¸&amp;#39; ëŒ€êµ¬ ì”¨ ë§ëë‹¤ (ì´ìŠˆë¼ì´...</td>\n",
       "      <td>ê²¨ìš¸ì²  ìƒì„ ì¸ ëŒ€êµ¬ ì–´íšëŸ‰ì´ í¬ê²Œ ì¤„ì–´ë“¤ì—ˆìŠµë‹ˆë‹¤. ì§€ë‚œí•´ì˜ 3ë¶„ì˜ 1ë„ ë¯¸ì¹˜ì§€ ëª»í•˜...</td>\n",
       "      <td>SBS ë‰´ìŠ¤</td>\n",
       "      <td>UCkinYTS9IHqOEwR1Sze2JTw</td>\n",
       "      <td>2025-01-07T02:43:45Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=UwvL4geTjuA</td>\n",
       "      <td>3027</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5080000</td>\n",
       "      <td>GSë¦¬í…Œì¼ ê³ ê° 9ë§Œëª… í•´í‚¹..&amp;#39;ê²¨ìš¸ë³„ë¯¸&amp;#39; ëŒ€êµ¬ ì”¨ ë§ëë‹¤ (ì´ìŠˆë¼ì´...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId                                              title  \\\n",
       "0  9GukLzTRkkM        ì£¼ì†Œì— í†µê´€ë²ˆí˜¸ê¹Œì§€â€¦GSë¦¬í…Œì¼, 158ë§Œëª… ì •ë³´ ìœ ì¶œ í™•ì¸ / JTBC ë‰´ìŠ¤ë£¸   \n",
       "1  qcQjIfuls3c    GSë¦¬í…Œì¼ ê³ ê° ì •ë³´ 9ë§Œì—¬ ê±´ í•´í‚¹ í”¼í•´â€¦3ì¼ ë§Œì— ì•Œë ¸ë‹¤ / SBS / #Dë¦¬í¬íŠ¸   \n",
       "2  ghSztNUxjB8              GSë¦¬í…Œì¼ ê³ ê° 9ë§Œ ëª… ê°œì¸ì •ë³´ ìœ ì¶œâ€¦í•´í‚¹ ê³µê²© / SBS 8ë‰´ìŠ¤   \n",
       "3  dAGkZUtGJ7Y  GSë¦¬í…Œì¼, í¸ì˜ì ì— í™ˆì‡¼í•‘ë„ í•´í‚¹â€¥158ë§Œ ê±´ ì¶”ê°€ ìœ ì¶œ (2025.02.27/ë‰´...   \n",
       "4  UwvL4geTjuA  GSë¦¬í…Œì¼ ê³ ê° 9ë§Œëª… í•´í‚¹..&#39;ê²¨ìš¸ë³„ë¯¸&#39; ëŒ€êµ¬ ì”¨ ë§ëë‹¤ (ì´ìŠˆë¼ì´...   \n",
       "\n",
       "                                         description channelTitle  \\\n",
       "0  ì§€ë‚œë‹¬ GSë¦¬í…Œì¼ì—ì„œë„ 9ë§Œ ëª…ì˜ ê°œì¸ì •ë³´ê°€ ìœ ì¶œë˜ëŠ” ì‚¬ê±´ì´ ë²Œì–´ì¡ŒìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ...    JTBC News   \n",
       "1  GSë¦¬í…Œì¼ì´ ê³ ê°ë“¤ì—ê²Œ ì˜¤ëŠ˜(6ì¼) ì˜¤í›„ ë°œì†¡í•œ í•´í‚¹ í”¼í•´ ê³µì§€ ë¬¸ì¡ë‹ˆë‹¤. ì§€ë‚œë‹¬ ...       SBS ë‰´ìŠ¤   \n",
       "2  GSë¦¬í…Œì¼ì´ ì§€ë‚œë‹¬ 27ì¼ë¶€í„° ì´ë‹¬ 4ì¼ ì‚¬ì´ ì›¹ì‚¬ì´íŠ¸ í•´í‚¹ ê³µê²©ì„ ë°›ì•„ ê³ ê° 9ë§Œ...       SBS ë‰´ìŠ¤   \n",
       "3  ì§€ë‚œë‹¬ í¸ì˜ì  í™ˆí˜ì´ì§€ì—ì„œ 9ë§Œì—¬ ëª…ì˜ ê°œì¸ì •ë³´ê°€ ìœ ì¶œëœ GSë¦¬í…Œì¼ì´ í™ˆì‡¼í•‘ ì›¹ì‚¬ì´...      MBCNEWS   \n",
       "4  ê²¨ìš¸ì²  ìƒì„ ì¸ ëŒ€êµ¬ ì–´íšëŸ‰ì´ í¬ê²Œ ì¤„ì–´ë“¤ì—ˆìŠµë‹ˆë‹¤. ì§€ë‚œí•´ì˜ 3ë¶„ì˜ 1ë„ ë¯¸ì¹˜ì§€ ëª»í•˜...       SBS ë‰´ìŠ¤   \n",
       "\n",
       "                  channelId           publishedAt  \\\n",
       "0  UCsU-I-vHLiaMfV_ceaYz5rQ  2025-02-27T11:45:38Z   \n",
       "1  UCkinYTS9IHqOEwR1Sze2JTw  2025-01-06T09:57:34Z   \n",
       "2  UCkinYTS9IHqOEwR1Sze2JTw  2025-01-06T12:38:57Z   \n",
       "3  UCF4Wxdo3inmxP-Y59wXDsFw  2025-02-27T06:24:05Z   \n",
       "4  UCkinYTS9IHqOEwR1Sze2JTw  2025-01-07T02:43:45Z   \n",
       "\n",
       "                                           url  viewCount  likeCount  \\\n",
       "0  https://www.youtube.com/watch?v=9GukLzTRkkM      13151        228   \n",
       "1  https://www.youtube.com/watch?v=qcQjIfuls3c       6297         68   \n",
       "2  https://www.youtube.com/watch?v=ghSztNUxjB8       4276         28   \n",
       "3  https://www.youtube.com/watch?v=dAGkZUtGJ7Y       3362         65   \n",
       "4  https://www.youtube.com/watch?v=UwvL4geTjuA       3027         10   \n",
       "\n",
       "   commentCount  subscriberCount  \\\n",
       "0           120          4750000   \n",
       "1            42          5080000   \n",
       "2            10          5080000   \n",
       "3            16          6040000   \n",
       "4             0          5080000   \n",
       "\n",
       "                                            text_raw gpt_post_sentiment  \\\n",
       "0  ì£¼ì†Œì— í†µê´€ë²ˆí˜¸ê¹Œì§€â€¦GSë¦¬í…Œì¼, 158ë§Œëª… ì •ë³´ ìœ ì¶œ í™•ì¸ / JTBC ë‰´ìŠ¤ë£¸ ì§€ë‚œ...                 ë¶€ì •   \n",
       "1  GSë¦¬í…Œì¼ ê³ ê° ì •ë³´ 9ë§Œì—¬ ê±´ í•´í‚¹ í”¼í•´â€¦3ì¼ ë§Œì— ì•Œë ¸ë‹¤ / SBS / #Dë¦¬í¬...                 ë¶€ì •   \n",
       "2  GSë¦¬í…Œì¼ ê³ ê° 9ë§Œ ëª… ê°œì¸ì •ë³´ ìœ ì¶œâ€¦í•´í‚¹ ê³µê²© / SBS 8ë‰´ìŠ¤ GSë¦¬í…Œì¼ì´ ì§€...                 ë¶€ì •   \n",
       "3  GSë¦¬í…Œì¼, í¸ì˜ì ì— í™ˆì‡¼í•‘ë„ í•´í‚¹â€¥158ë§Œ ê±´ ì¶”ê°€ ìœ ì¶œ (2025.02.27/ë‰´...                 ë¶€ì •   \n",
       "4  GSë¦¬í…Œì¼ ê³ ê° 9ë§Œëª… í•´í‚¹..&#39;ê²¨ìš¸ë³„ë¯¸&#39; ëŒ€êµ¬ ì”¨ ë§ëë‹¤ (ì´ìŠˆë¼ì´...                 ë¶€ì •   \n",
       "\n",
       "   gpt_post_confidence  \n",
       "0                 0.95  \n",
       "1                 0.92  \n",
       "2                 0.93  \n",
       "3                 0.94  \n",
       "4                 0.91  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ (Batch + JSON + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"ğŸ“Š GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥(ê²Œì‹œê¸€ì˜ ì œëª©ê³¼ ì„¤ëª…)ì˜ ì „ì²´ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼\n",
    "        ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê²Œì‹œê¸€ì˜ ê°ì •ì„ í‰ê°€í•˜ëŠ” ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ê²Œì‹œê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ------------------------------------------------------------\n",
    "input_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\GSë¦¬í…Œì¼_ì •ë³´ìœ ì¶œ_videos_20251103_154830.xlsx\"\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ ê²Œì‹œê¸€ í…ìŠ¤íŠ¸ ê²°í•© (ì œëª© + ì„¤ëª…)\n",
    "# ------------------------------------------------------------\n",
    "df[\"text_raw\"] = (\n",
    "    df.get(\"title\", \"\").astype(str).fillna(\"\") + \" \" + df.get(\"description\", \"\").astype(str).fillna(\"\")\n",
    ").str.strip().str[:500]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ (500ì)\n",
    "\n",
    "print(\"ì´ ê²Œì‹œê¸€ ìˆ˜:\", len(df))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"text_raw\"].tolist(), batch_size=20)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5ï¸âƒ£ ê²°ê³¼ ë°˜ì˜\n",
    "# ------------------------------------------------------------\n",
    "df[\"gpt_post_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_post_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6ï¸âƒ£ ê²°ê³¼ ì €ì¥\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\GS_posts_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ê²Œì‹œê¸€ ìˆ˜: 349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“Š GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [02:42<00:00,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\KT_posts_GPT_labeled.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>channelId</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>url</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>subscriberCount</th>\n",
       "      <th>text_raw</th>\n",
       "      <th>gpt_post_sentiment</th>\n",
       "      <th>gpt_post_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F0UQQT0tSD8</td>\n",
       "      <td>ê²°ì œ ë§‰íˆì 1ë¶„ ë’¤..KT í•´ì»¤ê°€ ì§ì ‘ ì“´ ê¸€ &amp;#39;ì¶©ê²©&amp;#39; #ë‰´ìŠ¤ë‹¤ /...</td>\n",
       "      <td>0:00 í”¼í•´ìë“¤ 'ê·¸ê³³' ì§€ë‚˜ë‹¤ë…”ë‹¤â€¦ì†Œì•¡ê²°ì œ ì‚¬íƒœ \"ë” í° ê³µê²© ëŒ€ë¹„í•´ì•¼\" (9....</td>\n",
       "      <td>JTBC News</td>\n",
       "      <td>UCsU-I-vHLiaMfV_ceaYz5rQ</td>\n",
       "      <td>2025-09-11T01:09:51Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=F0UQQT0tSD8</td>\n",
       "      <td>1291343</td>\n",
       "      <td>9573</td>\n",
       "      <td>3459</td>\n",
       "      <td>4750000</td>\n",
       "      <td>ê²°ì œ ë§‰íˆì 1ë¶„ ë’¤..KT í•´ì»¤ê°€ ì§ì ‘ ì“´ ê¸€ &amp;#39;ì¶©ê²©&amp;#39; #ë‰´ìŠ¤ë‹¤ /...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4eqeGxSyCts</td>\n",
       "      <td>&amp;quot;ì•„~~ì–´ë–¡í•´!&amp;quot; KTì–´í”Œ ë“¤ì–´ê°”ë‹¤ &amp;#39;ê²½ì•…&amp;#39;, ê´‘ëª…...</td>\n",
       "      <td>ìµœê·¼ ì„œìš¸ ê¸ˆì²œêµ¬ì™€ ê²½ê¸°ë„ ê´‘ëª…ì‹œì—ì„œ KT ì´ìš©ìì˜ íœ´ëŒ€ì „í™”ì—ì„œ ì†Œì•¡ ê²°ì œë¡œ ìˆ˜ì‹­ë§Œ...</td>\n",
       "      <td>MBCNEWS</td>\n",
       "      <td>UCF4Wxdo3inmxP-Y59wXDsFw</td>\n",
       "      <td>2025-09-10T06:56:21Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=4eqeGxSyCts</td>\n",
       "      <td>888588</td>\n",
       "      <td>6269</td>\n",
       "      <td>1002</td>\n",
       "      <td>6040000</td>\n",
       "      <td>&amp;quot;ì•„~~ì–´ë–¡í•´!&amp;quot; KTì–´í”Œ ë“¤ì–´ê°”ë‹¤ &amp;#39;ê²½ì•…&amp;#39;, ê´‘ëª…...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_QuSUseohg0</td>\n",
       "      <td>[ìë§‰ë‰´ìŠ¤] ì•Œì•„ì°¨ë¦° ì¹´ì´ìŠ¤íŠ¸, KTì— ì•Œë ¸ë‹¤â€¦ë’¤ëŠ¦ê²Œ ë°í˜€ì§„ ì‚¬ì‹¤ / JTBC News</td>\n",
       "      <td>ì´ë²ˆ ì‚¬íƒœëŠ” ì „ë¬¸ê°€ë“¤ì´ 10ë…„ ì „ë¶€í„° ìš°ë ¤í–ˆë˜ ì¼ì…ë‹ˆë‹¤. 2014ë…„, êµ­ë‚´ í•œ ì—°êµ¬...</td>\n",
       "      <td>JTBC News</td>\n",
       "      <td>UCsU-I-vHLiaMfV_ceaYz5rQ</td>\n",
       "      <td>2025-09-13T02:00:29Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=_QuSUseohg0</td>\n",
       "      <td>817923</td>\n",
       "      <td>6693</td>\n",
       "      <td>1321</td>\n",
       "      <td>4750000</td>\n",
       "      <td>[ìë§‰ë‰´ìŠ¤] ì•Œì•„ì°¨ë¦° ì¹´ì´ìŠ¤íŠ¸, KTì— ì•Œë ¸ë‹¤â€¦ë’¤ëŠ¦ê²Œ ë°í˜€ì§„ ì‚¬ì‹¤ / JTBC Ne...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49Qf4b7bWMM</td>\n",
       "      <td>KT ëŒ€í‘œ ê³ ê°œ ìˆ™ì˜€ë‹¤â€¦&amp;quot;ìœ ì‹¬ ì „ë©´ êµì²´Â·ì „ì•¡ ë³´ìƒí•  ê²ƒ&amp;quot; / SBS</td>\n",
       "      <td>ã€ˆì•µì»¤ã€‰ ìµœê·¼ ë°œìƒí•œ ë¬´ë‹¨ ì†Œì•¡ê²°ì œ ì‚¬íƒœì™€ ê´€ë ¨í•´, KTê°€ 5ì²œ5ë°±ì—¬ ëª…ì˜ ê°œì¸ì •ë³´...</td>\n",
       "      <td>SBS ë‰´ìŠ¤</td>\n",
       "      <td>UCkinYTS9IHqOEwR1Sze2JTw</td>\n",
       "      <td>2025-09-11T08:27:46Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=49Qf4b7bWMM</td>\n",
       "      <td>786671</td>\n",
       "      <td>3663</td>\n",
       "      <td>2886</td>\n",
       "      <td>5080000</td>\n",
       "      <td>KT ëŒ€í‘œ ê³ ê°œ ìˆ™ì˜€ë‹¤â€¦&amp;quot;ìœ ì‹¬ ì „ë©´ êµì²´Â·ì „ì•¡ ë³´ìƒí•  ê²ƒ&amp;quot; / S...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JejEYG3CfsM</td>\n",
       "      <td>[ë‹¨ë…] &amp;quot;ìœ ë ¹ ê¸°ì§€êµ­ ë§Œë“¤ì–´ KTë§ í•´í‚¹â€¥ë‹¤ë¥¸ ì§€ì—­ìœ¼ë¡œ ì´ë™ë„ ê°€ëŠ¥&amp;qu...</td>\n",
       "      <td>ìµœê·¼ KT íœ´ëŒ€ì „í™” ê°€ì…ìë“¤ë¡œë¶€í„° ì†Œì•¡ ê²°ì œë¥¼ í†µí•´ ìˆ˜ì‹­ë§Œ ì›ì”©ì´ ë¹ ì ¸ë‚˜ê°„ ì‚¬ê±´ì— ...</td>\n",
       "      <td>MBCNEWS</td>\n",
       "      <td>UCF4Wxdo3inmxP-Y59wXDsFw</td>\n",
       "      <td>2025-09-09T10:59:40Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=JejEYG3CfsM</td>\n",
       "      <td>650828</td>\n",
       "      <td>6807</td>\n",
       "      <td>2827</td>\n",
       "      <td>6040000</td>\n",
       "      <td>[ë‹¨ë…] &amp;quot;ìœ ë ¹ ê¸°ì§€êµ­ ë§Œë“¤ì–´ KTë§ í•´í‚¹â€¥ë‹¤ë¥¸ ì§€ì—­ìœ¼ë¡œ ì´ë™ë„ ê°€ëŠ¥&amp;qu...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId                                              title  \\\n",
       "0  F0UQQT0tSD8  ê²°ì œ ë§‰íˆì 1ë¶„ ë’¤..KT í•´ì»¤ê°€ ì§ì ‘ ì“´ ê¸€ &#39;ì¶©ê²©&#39; #ë‰´ìŠ¤ë‹¤ /...   \n",
       "1  4eqeGxSyCts  &quot;ì•„~~ì–´ë–¡í•´!&quot; KTì–´í”Œ ë“¤ì–´ê°”ë‹¤ &#39;ê²½ì•…&#39;, ê´‘ëª…...   \n",
       "2  _QuSUseohg0   [ìë§‰ë‰´ìŠ¤] ì•Œì•„ì°¨ë¦° ì¹´ì´ìŠ¤íŠ¸, KTì— ì•Œë ¸ë‹¤â€¦ë’¤ëŠ¦ê²Œ ë°í˜€ì§„ ì‚¬ì‹¤ / JTBC News   \n",
       "3  49Qf4b7bWMM   KT ëŒ€í‘œ ê³ ê°œ ìˆ™ì˜€ë‹¤â€¦&quot;ìœ ì‹¬ ì „ë©´ êµì²´Â·ì „ì•¡ ë³´ìƒí•  ê²ƒ&quot; / SBS   \n",
       "4  JejEYG3CfsM  [ë‹¨ë…] &quot;ìœ ë ¹ ê¸°ì§€êµ­ ë§Œë“¤ì–´ KTë§ í•´í‚¹â€¥ë‹¤ë¥¸ ì§€ì—­ìœ¼ë¡œ ì´ë™ë„ ê°€ëŠ¥&qu...   \n",
       "\n",
       "                                         description channelTitle  \\\n",
       "0  0:00 í”¼í•´ìë“¤ 'ê·¸ê³³' ì§€ë‚˜ë‹¤ë…”ë‹¤â€¦ì†Œì•¡ê²°ì œ ì‚¬íƒœ \"ë” í° ê³µê²© ëŒ€ë¹„í•´ì•¼\" (9....    JTBC News   \n",
       "1  ìµœê·¼ ì„œìš¸ ê¸ˆì²œêµ¬ì™€ ê²½ê¸°ë„ ê´‘ëª…ì‹œì—ì„œ KT ì´ìš©ìì˜ íœ´ëŒ€ì „í™”ì—ì„œ ì†Œì•¡ ê²°ì œë¡œ ìˆ˜ì‹­ë§Œ...      MBCNEWS   \n",
       "2  ì´ë²ˆ ì‚¬íƒœëŠ” ì „ë¬¸ê°€ë“¤ì´ 10ë…„ ì „ë¶€í„° ìš°ë ¤í–ˆë˜ ì¼ì…ë‹ˆë‹¤. 2014ë…„, êµ­ë‚´ í•œ ì—°êµ¬...    JTBC News   \n",
       "3  ã€ˆì•µì»¤ã€‰ ìµœê·¼ ë°œìƒí•œ ë¬´ë‹¨ ì†Œì•¡ê²°ì œ ì‚¬íƒœì™€ ê´€ë ¨í•´, KTê°€ 5ì²œ5ë°±ì—¬ ëª…ì˜ ê°œì¸ì •ë³´...       SBS ë‰´ìŠ¤   \n",
       "4  ìµœê·¼ KT íœ´ëŒ€ì „í™” ê°€ì…ìë“¤ë¡œë¶€í„° ì†Œì•¡ ê²°ì œë¥¼ í†µí•´ ìˆ˜ì‹­ë§Œ ì›ì”©ì´ ë¹ ì ¸ë‚˜ê°„ ì‚¬ê±´ì— ...      MBCNEWS   \n",
       "\n",
       "                  channelId           publishedAt  \\\n",
       "0  UCsU-I-vHLiaMfV_ceaYz5rQ  2025-09-11T01:09:51Z   \n",
       "1  UCF4Wxdo3inmxP-Y59wXDsFw  2025-09-10T06:56:21Z   \n",
       "2  UCsU-I-vHLiaMfV_ceaYz5rQ  2025-09-13T02:00:29Z   \n",
       "3  UCkinYTS9IHqOEwR1Sze2JTw  2025-09-11T08:27:46Z   \n",
       "4  UCF4Wxdo3inmxP-Y59wXDsFw  2025-09-09T10:59:40Z   \n",
       "\n",
       "                                           url  viewCount  likeCount  \\\n",
       "0  https://www.youtube.com/watch?v=F0UQQT0tSD8    1291343       9573   \n",
       "1  https://www.youtube.com/watch?v=4eqeGxSyCts     888588       6269   \n",
       "2  https://www.youtube.com/watch?v=_QuSUseohg0     817923       6693   \n",
       "3  https://www.youtube.com/watch?v=49Qf4b7bWMM     786671       3663   \n",
       "4  https://www.youtube.com/watch?v=JejEYG3CfsM     650828       6807   \n",
       "\n",
       "   commentCount  subscriberCount  \\\n",
       "0          3459          4750000   \n",
       "1          1002          6040000   \n",
       "2          1321          4750000   \n",
       "3          2886          5080000   \n",
       "4          2827          6040000   \n",
       "\n",
       "                                            text_raw gpt_post_sentiment  \\\n",
       "0  ê²°ì œ ë§‰íˆì 1ë¶„ ë’¤..KT í•´ì»¤ê°€ ì§ì ‘ ì“´ ê¸€ &#39;ì¶©ê²©&#39; #ë‰´ìŠ¤ë‹¤ /...                 ë¶€ì •   \n",
       "1  &quot;ì•„~~ì–´ë–¡í•´!&quot; KTì–´í”Œ ë“¤ì–´ê°”ë‹¤ &#39;ê²½ì•…&#39;, ê´‘ëª…...                 ë¶€ì •   \n",
       "2  [ìë§‰ë‰´ìŠ¤] ì•Œì•„ì°¨ë¦° ì¹´ì´ìŠ¤íŠ¸, KTì— ì•Œë ¸ë‹¤â€¦ë’¤ëŠ¦ê²Œ ë°í˜€ì§„ ì‚¬ì‹¤ / JTBC Ne...                 ë¶€ì •   \n",
       "3  KT ëŒ€í‘œ ê³ ê°œ ìˆ™ì˜€ë‹¤â€¦&quot;ìœ ì‹¬ ì „ë©´ êµì²´Â·ì „ì•¡ ë³´ìƒí•  ê²ƒ&quot; / S...                 ë¶€ì •   \n",
       "4  [ë‹¨ë…] &quot;ìœ ë ¹ ê¸°ì§€êµ­ ë§Œë“¤ì–´ KTë§ í•´í‚¹â€¥ë‹¤ë¥¸ ì§€ì—­ìœ¼ë¡œ ì´ë™ë„ ê°€ëŠ¥&qu...                 ë¶€ì •   \n",
       "\n",
       "   gpt_post_confidence  \n",
       "0                 0.95  \n",
       "1                 0.92  \n",
       "2                 0.90  \n",
       "3                 0.93  \n",
       "4                 0.94  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ (Batch + JSON + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"ğŸ“Š GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥(ê²Œì‹œê¸€ì˜ ì œëª©ê³¼ ì„¤ëª…)ì˜ ì „ì²´ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼\n",
    "        ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê²Œì‹œê¸€ì˜ ê°ì •ì„ í‰ê°€í•˜ëŠ” ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ê²Œì‹œê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ------------------------------------------------------------\n",
    "input_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\KT_í¨í† ì…€_í•´í‚¹_videos_20251103_152106.xlsx\"\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ ê²Œì‹œê¸€ í…ìŠ¤íŠ¸ ê²°í•© (ì œëª© + ì„¤ëª…)\n",
    "# ------------------------------------------------------------\n",
    "df[\"text_raw\"] = (\n",
    "    df.get(\"title\", \"\").astype(str).fillna(\"\") + \" \" + df.get(\"description\", \"\").astype(str).fillna(\"\")\n",
    ").str.strip().str[:500]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ (500ì)\n",
    "\n",
    "print(\"ì´ ê²Œì‹œê¸€ ìˆ˜:\", len(df))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"text_raw\"].tolist(), batch_size=20)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5ï¸âƒ£ ê²°ê³¼ ë°˜ì˜\n",
    "# ------------------------------------------------------------\n",
    "df[\"gpt_post_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_post_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6ï¸âƒ£ ê²°ê³¼ ì €ì¥\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\KT_posts_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ê²Œì‹œê¸€ ìˆ˜: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“Š GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [03:43<00:00,  8.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\skt_posts_GPT_labeled.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>channelId</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>url</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>subscriberCount</th>\n",
       "      <th>text_raw</th>\n",
       "      <th>gpt_post_sentiment</th>\n",
       "      <th>gpt_post_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3B6nv74tSkw</td>\n",
       "      <td>ì§€ê¸ˆ ìœ ì‹¬ì´ ë¬¸ì œê°€ ì•„ë‹™ë‹ˆë‹¤ ì´ê±°ë¶€í„° ë‹¹ì¥ ë„ì„¸ìš”! (ëª¨ë“  í†µì‹ ì‚¬ ê³µí†µ)</td>\n",
       "      <td>1ë¶„ë¯¸ë§Œ #ê¿€íŒ #ìœ ì‹¬ #ìœ ì¶œ #ì„¤ì • #ì •ë³´.</td>\n",
       "      <td>1ë¶„ë¯¸ë§Œ</td>\n",
       "      <td>UC2xkO7XCiStWfR3fKbzkbqw</td>\n",
       "      <td>2025-04-26T08:19:53Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=3B6nv74tSkw</td>\n",
       "      <td>4730371</td>\n",
       "      <td>130601</td>\n",
       "      <td>5631</td>\n",
       "      <td>2570000</td>\n",
       "      <td>ì§€ê¸ˆ ìœ ì‹¬ì´ ë¬¸ì œê°€ ì•„ë‹™ë‹ˆë‹¤ ì´ê±°ë¶€í„° ë‹¹ì¥ ë„ì„¸ìš”! (ëª¨ë“  í†µì‹ ì‚¬ ê³µí†µ) 1ë¶„ë¯¸ë§Œ ...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6qYETkvx4cY</td>\n",
       "      <td>íœ´ëŒ€í° ì´ê±° ì•ˆ ë„ë©´ ë‹¤ í„¸ë¦½ë‹ˆë‹¤. ë¹¨ë¦¬ ë„ì„¸ìš”!</td>\n",
       "      <td>ë‚´ ê°œì¸ì •ë³´ë„ í˜¹ì‹œ...? ì±„ë„ì— ê°€ì…í•˜ì—¬ í˜œíƒì„ ëˆ„ë ¤ë³´ì„¸ìš”.</td>\n",
       "      <td>í‘œì˜í˜¸ tv  / ê²½ì œì  ììœ ì™€ í–‰ë³µì„ ìœ„í•˜ì—¬</td>\n",
       "      <td>UCp8lZRI3NSCXxhn_a_WGVKQ</td>\n",
       "      <td>2025-04-28T10:30:06Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=6qYETkvx4cY</td>\n",
       "      <td>3617269</td>\n",
       "      <td>67184</td>\n",
       "      <td>3981</td>\n",
       "      <td>810000</td>\n",
       "      <td>íœ´ëŒ€í° ì´ê±° ì•ˆ ë„ë©´ ë‹¤ í„¸ë¦½ë‹ˆë‹¤. ë¹¨ë¦¬ ë„ì„¸ìš”! ë‚´ ê°œì¸ì •ë³´ë„ í˜¹ì‹œ...? ì±„ë„ì—...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yPFP6QcL_wI</td>\n",
       "      <td>ìµœì•…ì˜ ì‚¬íƒœì™€ ëŒ€ì‘.. SKT ìœ ì‹¬ í•´í‚¹&amp;amp;í”¼í•´ ëŒ€ì²˜ë²• ì´ì •ë¦¬</td>\n",
       "      <td>SKT í•´í‚¹ ì‚¬íƒœê°€ í„°ì§„ í›„ ë‹¹ì¼ ì†Œì‹ê³¼ ì´ˆê¸° ëŒ€ì‘ ë°©ë²•ì„ ì»¤ë®¤ë‹ˆí‹°ì— ê³µìœ í–ˆê³ , S...</td>\n",
       "      <td>ITSubì‡ì„­</td>\n",
       "      <td>UCdUcjkyZtf-1WJyPPiETF1g</td>\n",
       "      <td>2025-04-28T10:30:42Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=yPFP6QcL_wI</td>\n",
       "      <td>3256113</td>\n",
       "      <td>80039</td>\n",
       "      <td>10238</td>\n",
       "      <td>2780000</td>\n",
       "      <td>ìµœì•…ì˜ ì‚¬íƒœì™€ ëŒ€ì‘.. SKT ìœ ì‹¬ í•´í‚¹&amp;amp;í”¼í•´ ëŒ€ì²˜ë²• ì´ì •ë¦¬ SKT í•´í‚¹ ì‚¬...</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P5UiGz68mZk</td>\n",
       "      <td>&amp;quot;í•¸ë“œí° êº¼ë†“ëŠ” ìˆœê°„&amp;quot;â€¦SKTí° &amp;#39;ì´ê±´ í•˜ì§€ ë§ì•„ì•¼&amp;#39...</td>\n",
       "      <td>0:00 'ìœ ì‹¬ë³´í˜¸' ê³ ê°ì— í•˜ë¼ëŠ” SKTâ€¦ì˜¤í”ˆëŸ° í•´ë„ \"ì¬ê³  ì—†ì–´ìš”\" (4.28 ...</td>\n",
       "      <td>JTBC News</td>\n",
       "      <td>UCsU-I-vHLiaMfV_ceaYz5rQ</td>\n",
       "      <td>2025-04-29T00:55:01Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=P5UiGz68mZk</td>\n",
       "      <td>2844108</td>\n",
       "      <td>19354</td>\n",
       "      <td>3419</td>\n",
       "      <td>4750000</td>\n",
       "      <td>&amp;quot;í•¸ë“œí° êº¼ë†“ëŠ” ìˆœê°„&amp;quot;â€¦SKTí° &amp;#39;ì´ê±´ í•˜ì§€ ë§ì•„ì•¼&amp;#39...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rlaKrI4bjQs</td>\n",
       "      <td>skt ìœ ì‹¬í•´í‚¹ì´í›„ ëŒ€ì²˜ë²• ë¹¨ë¦¬í•˜ì„¸ìš”!</td>\n",
       "      <td>ì™„ì „ ë‚œë¦¬ë‚œ skt ìœ ì‹¬í•´í‚¹ì´í›„ ëŒ€ì²˜ë²• ë¹¨ë¦¬í•˜ì„¸ìš”!</td>\n",
       "      <td>ë§Œë ™ë°±ìˆ˜</td>\n",
       "      <td>UCn8tvVLoVaPP4MjDwMff5MA</td>\n",
       "      <td>2025-04-26T12:11:40Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=rlaKrI4bjQs</td>\n",
       "      <td>5343517</td>\n",
       "      <td>91543</td>\n",
       "      <td>2318</td>\n",
       "      <td>89200</td>\n",
       "      <td>skt ìœ ì‹¬í•´í‚¹ì´í›„ ëŒ€ì²˜ë²• ë¹¨ë¦¬í•˜ì„¸ìš”! ì™„ì „ ë‚œë¦¬ë‚œ skt ìœ ì‹¬í•´í‚¹ì´í›„ ëŒ€ì²˜ë²• ë¹¨ë¦¬...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId                                              title  \\\n",
       "0  3B6nv74tSkw           ì§€ê¸ˆ ìœ ì‹¬ì´ ë¬¸ì œê°€ ì•„ë‹™ë‹ˆë‹¤ ì´ê±°ë¶€í„° ë‹¹ì¥ ë„ì„¸ìš”! (ëª¨ë“  í†µì‹ ì‚¬ ê³µí†µ)   \n",
       "1  6qYETkvx4cY                        íœ´ëŒ€í° ì´ê±° ì•ˆ ë„ë©´ ë‹¤ í„¸ë¦½ë‹ˆë‹¤. ë¹¨ë¦¬ ë„ì„¸ìš”!   \n",
       "2  yPFP6QcL_wI              ìµœì•…ì˜ ì‚¬íƒœì™€ ëŒ€ì‘.. SKT ìœ ì‹¬ í•´í‚¹&amp;í”¼í•´ ëŒ€ì²˜ë²• ì´ì •ë¦¬   \n",
       "3  P5UiGz68mZk  &quot;í•¸ë“œí° êº¼ë†“ëŠ” ìˆœê°„&quot;â€¦SKTí° &#39;ì´ê±´ í•˜ì§€ ë§ì•„ì•¼&#39...   \n",
       "4  rlaKrI4bjQs                              skt ìœ ì‹¬í•´í‚¹ì´í›„ ëŒ€ì²˜ë²• ë¹¨ë¦¬í•˜ì„¸ìš”!   \n",
       "\n",
       "                                         description  \\\n",
       "0                          1ë¶„ë¯¸ë§Œ #ê¿€íŒ #ìœ ì‹¬ #ìœ ì¶œ #ì„¤ì • #ì •ë³´.   \n",
       "1                 ë‚´ ê°œì¸ì •ë³´ë„ í˜¹ì‹œ...? ì±„ë„ì— ê°€ì…í•˜ì—¬ í˜œíƒì„ ëˆ„ë ¤ë³´ì„¸ìš”.   \n",
       "2  SKT í•´í‚¹ ì‚¬íƒœê°€ í„°ì§„ í›„ ë‹¹ì¼ ì†Œì‹ê³¼ ì´ˆê¸° ëŒ€ì‘ ë°©ë²•ì„ ì»¤ë®¤ë‹ˆí‹°ì— ê³µìœ í–ˆê³ , S...   \n",
       "3  0:00 'ìœ ì‹¬ë³´í˜¸' ê³ ê°ì— í•˜ë¼ëŠ” SKTâ€¦ì˜¤í”ˆëŸ° í•´ë„ \"ì¬ê³  ì—†ì–´ìš”\" (4.28 ...   \n",
       "4                       ì™„ì „ ë‚œë¦¬ë‚œ skt ìœ ì‹¬í•´í‚¹ì´í›„ ëŒ€ì²˜ë²• ë¹¨ë¦¬í•˜ì„¸ìš”!   \n",
       "\n",
       "                channelTitle                 channelId           publishedAt  \\\n",
       "0                       1ë¶„ë¯¸ë§Œ  UC2xkO7XCiStWfR3fKbzkbqw  2025-04-26T08:19:53Z   \n",
       "1  í‘œì˜í˜¸ tv  / ê²½ì œì  ììœ ì™€ í–‰ë³µì„ ìœ„í•˜ì—¬  UCp8lZRI3NSCXxhn_a_WGVKQ  2025-04-28T10:30:06Z   \n",
       "2                    ITSubì‡ì„­  UCdUcjkyZtf-1WJyPPiETF1g  2025-04-28T10:30:42Z   \n",
       "3                  JTBC News  UCsU-I-vHLiaMfV_ceaYz5rQ  2025-04-29T00:55:01Z   \n",
       "4                       ë§Œë ™ë°±ìˆ˜  UCn8tvVLoVaPP4MjDwMff5MA  2025-04-26T12:11:40Z   \n",
       "\n",
       "                                           url  viewCount  likeCount  \\\n",
       "0  https://www.youtube.com/watch?v=3B6nv74tSkw    4730371     130601   \n",
       "1  https://www.youtube.com/watch?v=6qYETkvx4cY    3617269      67184   \n",
       "2  https://www.youtube.com/watch?v=yPFP6QcL_wI    3256113      80039   \n",
       "3  https://www.youtube.com/watch?v=P5UiGz68mZk    2844108      19354   \n",
       "4  https://www.youtube.com/watch?v=rlaKrI4bjQs    5343517      91543   \n",
       "\n",
       "   commentCount  subscriberCount  \\\n",
       "0          5631          2570000   \n",
       "1          3981           810000   \n",
       "2         10238          2780000   \n",
       "3          3419          4750000   \n",
       "4          2318            89200   \n",
       "\n",
       "                                            text_raw gpt_post_sentiment  \\\n",
       "0  ì§€ê¸ˆ ìœ ì‹¬ì´ ë¬¸ì œê°€ ì•„ë‹™ë‹ˆë‹¤ ì´ê±°ë¶€í„° ë‹¹ì¥ ë„ì„¸ìš”! (ëª¨ë“  í†µì‹ ì‚¬ ê³µí†µ) 1ë¶„ë¯¸ë§Œ ...                 ë¶€ì •   \n",
       "1  íœ´ëŒ€í° ì´ê±° ì•ˆ ë„ë©´ ë‹¤ í„¸ë¦½ë‹ˆë‹¤. ë¹¨ë¦¬ ë„ì„¸ìš”! ë‚´ ê°œì¸ì •ë³´ë„ í˜¹ì‹œ...? ì±„ë„ì—...                 ë¶€ì •   \n",
       "2  ìµœì•…ì˜ ì‚¬íƒœì™€ ëŒ€ì‘.. SKT ìœ ì‹¬ í•´í‚¹&amp;í”¼í•´ ëŒ€ì²˜ë²• ì´ì •ë¦¬ SKT í•´í‚¹ ì‚¬...                 ì¤‘ë¦½   \n",
       "3  &quot;í•¸ë“œí° êº¼ë†“ëŠ” ìˆœê°„&quot;â€¦SKTí° &#39;ì´ê±´ í•˜ì§€ ë§ì•„ì•¼&#39...                 ë¶€ì •   \n",
       "4  skt ìœ ì‹¬í•´í‚¹ì´í›„ ëŒ€ì²˜ë²• ë¹¨ë¦¬í•˜ì„¸ìš”! ì™„ì „ ë‚œë¦¬ë‚œ skt ìœ ì‹¬í•´í‚¹ì´í›„ ëŒ€ì²˜ë²• ë¹¨ë¦¬...                 ë¶€ì •   \n",
       "\n",
       "   gpt_post_confidence  \n",
       "0                 0.95  \n",
       "1                 0.92  \n",
       "2                 0.60  \n",
       "3                 0.90  \n",
       "4                 0.93  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ (Batch + JSON + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"ğŸ“Š GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥(ê²Œì‹œê¸€ì˜ ì œëª©ê³¼ ì„¤ëª…)ì˜ ì „ì²´ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼\n",
    "        ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê²Œì‹œê¸€ì˜ ê°ì •ì„ í‰ê°€í•˜ëŠ” ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ê²Œì‹œê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ------------------------------------------------------------\n",
    "input_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\SKT_ìœ ì‹¬ì¹©_ìœ ì¶œ_videos_20251103_165204.xlsx\"\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ ê²Œì‹œê¸€ í…ìŠ¤íŠ¸ ê²°í•© (ì œëª© + ì„¤ëª…)\n",
    "# ------------------------------------------------------------\n",
    "df[\"text_raw\"] = (\n",
    "    df.get(\"title\", \"\").astype(str).fillna(\"\") + \" \" + df.get(\"description\", \"\").astype(str).fillna(\"\")\n",
    ").str.strip().str[:500]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ (500ì)\n",
    "\n",
    "print(\"ì´ ê²Œì‹œê¸€ ìˆ˜:\", len(df))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"text_raw\"].tolist(), batch_size=20)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5ï¸âƒ£ ê²°ê³¼ ë°˜ì˜\n",
    "# ------------------------------------------------------------\n",
    "df[\"gpt_post_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_post_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6ï¸âƒ£ ê²°ê³¼ ì €ì¥\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\skt_posts_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ê²Œì‹œê¸€ ìˆ˜: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“Š GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [04:49<00:00, 11.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\ë¡¯ë°ë°_posts_GPT_labeled.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>channelId</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>url</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>subscriberCount</th>\n",
       "      <th>text_raw</th>\n",
       "      <th>gpt_post_sentiment</th>\n",
       "      <th>gpt_post_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VaBG145v0UM</td>\n",
       "      <td>[ìë§‰ë‰´ìŠ¤] ë¡¯ë°ì¹´ë“œ ì“°ëŠ”ë°, &amp;#39;ì´ ë¬¸ì&amp;#39; ë°›ì•˜ë‹¤ë©´ ë‹¹ì¥ ì¹´ë“œ í•´ì§€í•˜...</td>\n",
       "      <td>í•´í‚¹ì€ ì§€ë‚œë‹¬ 14ì¼ ì‹œì‘ëìŠµë‹ˆë‹¤. ì•…ì„±ì½”ë“œë¡œ ì˜¨ë¼ì¸ ê²°ì œ ì„œë²„ë¥¼ ëš«ì—ˆê³ , í•´ì»¤ë“¤ì€...</td>\n",
       "      <td>KBS News</td>\n",
       "      <td>UCcQTRi69dsVYHN3exePtZ1A</td>\n",
       "      <td>2025-09-19T01:35:02Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=VaBG145v0UM</td>\n",
       "      <td>638378</td>\n",
       "      <td>3443</td>\n",
       "      <td>875</td>\n",
       "      <td>3480000</td>\n",
       "      <td>[ìë§‰ë‰´ìŠ¤] ë¡¯ë°ì¹´ë“œ ì“°ëŠ”ë°, &amp;#39;ì´ ë¬¸ì&amp;#39; ë°›ì•˜ë‹¤ë©´ ë‹¹ì¥ ì¹´ë“œ í•´ì§€í•˜...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4XwhXsUVHN0</td>\n",
       "      <td>ì¶©ê²©ì  ì‚¬ì‹¤! ì™¸êµ­ í•´ì»¤ì—ê²Œ ì™„ì „íˆ ëš«ë¦° í•œêµ­ì •ë¶€ê¸°ê´€! [ì½”ë„ˆë³„ ë‹¤ì‹œë³´ê¸°]</td>\n",
       "      <td>ë§¤ë¶ˆì‡¼ #ìµœìš± #ë¡¯ë°ì¹´ë“œ #KT - ë³´ì•ˆ íŠ¹ì§‘ : ê¹€ìŠ¹ì£¼ X ì˜¤ìœ¤í˜œ --------...</td>\n",
       "      <td>[íŒŸë¹µ] ë§¤ë¶ˆì‡¼</td>\n",
       "      <td>UCMYhq9OyGI5UEz_NTAoHY7A</td>\n",
       "      <td>2025-09-22T11:42:16Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=4XwhXsUVHN0</td>\n",
       "      <td>302503</td>\n",
       "      <td>8080</td>\n",
       "      <td>503</td>\n",
       "      <td>2830000</td>\n",
       "      <td>ì¶©ê²©ì  ì‚¬ì‹¤! ì™¸êµ­ í•´ì»¤ì—ê²Œ ì™„ì „íˆ ëš«ë¦° í•œêµ­ì •ë¶€ê¸°ê´€! [ì½”ë„ˆë³„ ë‹¤ì‹œë³´ê¸°] ë§¤ë¶ˆì‡¼ ...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rc87JZwNqFA</td>\n",
       "      <td>[ë‹¨ë…] ë¡¯ë°ì¹´ë“œ í•´í‚¹ì—ì„œë„â€¦ì†Œë¦„ ë‹ëŠ” ê³µí†µì  ì°¾ì•˜ë‹¤ / SBS 8ë‰´ìŠ¤</td>\n",
       "      <td>ã€ˆì•µì»¤ã€‰ 297ë§Œ ëª…ì— ë‹¬í•˜ëŠ” ê°œì¸ì •ë³´ê°€ í„¸ë¦° ë¡¯ë°ì¹´ë“œ í•´í‚¹ ì‚¬íƒœê°€, ì¤‘êµ­ í•´í‚¹ ì¡°...</td>\n",
       "      <td>SBS ë‰´ìŠ¤</td>\n",
       "      <td>UCkinYTS9IHqOEwR1Sze2JTw</td>\n",
       "      <td>2025-10-01T12:00:22Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=rc87JZwNqFA</td>\n",
       "      <td>285226</td>\n",
       "      <td>7523</td>\n",
       "      <td>3774</td>\n",
       "      <td>5080000</td>\n",
       "      <td>[ë‹¨ë…] ë¡¯ë°ì¹´ë“œ í•´í‚¹ì—ì„œë„â€¦ì†Œë¦„ ë‹ëŠ” ê³µí†µì  ì°¾ì•˜ë‹¤ / SBS 8ë‰´ìŠ¤ ã€ˆì•µì»¤ã€‰ 2...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7Pr_Vvn-4Og</td>\n",
       "      <td>[ë‹¨ë…] &amp;quot;LG U+, KTë„ í„¸ë ¸ë‹¤â€¥&amp;#39;í•´í‚¹ ì•„ëƒ&amp;#39; ë²„í‹°ê¸°ì—...</td>\n",
       "      <td>SKí…”ë ˆì½¤ì—ì„œ 2ì²œ3ë°±ë§Œ ê°€ì…ì ì •ë³´ê°€ ìœ ì¶œë¼, ìœ ì‹¬ ëŒ€ë€ì´ ë²Œì–´ì§„ ê²Œ ë„‰ ë‹¬ ì „ì´...</td>\n",
       "      <td>MBCNEWS</td>\n",
       "      <td>UCF4Wxdo3inmxP-Y59wXDsFw</td>\n",
       "      <td>2025-09-01T11:50:17Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=7Pr_Vvn-4Og</td>\n",
       "      <td>268457</td>\n",
       "      <td>3218</td>\n",
       "      <td>1215</td>\n",
       "      <td>6040000</td>\n",
       "      <td>[ë‹¨ë…] &amp;quot;LG U+, KTë„ í„¸ë ¸ë‹¤â€¥&amp;#39;í•´í‚¹ ì•„ëƒ&amp;#39; ë²„í‹°ê¸°ì—...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GnYiq1DhdtI</td>\n",
       "      <td>[ë‹¨ë…] ë¡¯ë°ì¹´ë“œ, ë¶€ì •ì‚¬ìš© ì—†ë‹¤ë”ë‹ˆâ€¥2ì°¨ &amp;#39;í”¼ì‹±&amp;#39; ê³µê²© í™•ì¸ (20...</td>\n",
       "      <td>297ë§Œ ëª…ì˜ ê°œì¸ì •ë³´ê°€ ìœ ì¶œëœ ë¡¯ë°ì¹´ë“œ í•´í‚¹ ì‚¬íƒœì˜ íŒŒì¥ì´ í™•ì‚°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ìœ ...</td>\n",
       "      <td>MBCNEWS</td>\n",
       "      <td>UCF4Wxdo3inmxP-Y59wXDsFw</td>\n",
       "      <td>2025-09-19T10:53:51Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=GnYiq1DhdtI</td>\n",
       "      <td>211262</td>\n",
       "      <td>2180</td>\n",
       "      <td>546</td>\n",
       "      <td>6040000</td>\n",
       "      <td>[ë‹¨ë…] ë¡¯ë°ì¹´ë“œ, ë¶€ì •ì‚¬ìš© ì—†ë‹¤ë”ë‹ˆâ€¥2ì°¨ &amp;#39;í”¼ì‹±&amp;#39; ê³µê²© í™•ì¸ (20...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId                                              title  \\\n",
       "0  VaBG145v0UM  [ìë§‰ë‰´ìŠ¤] ë¡¯ë°ì¹´ë“œ ì“°ëŠ”ë°, &#39;ì´ ë¬¸ì&#39; ë°›ì•˜ë‹¤ë©´ ë‹¹ì¥ ì¹´ë“œ í•´ì§€í•˜...   \n",
       "1  4XwhXsUVHN0          ì¶©ê²©ì  ì‚¬ì‹¤! ì™¸êµ­ í•´ì»¤ì—ê²Œ ì™„ì „íˆ ëš«ë¦° í•œêµ­ì •ë¶€ê¸°ê´€! [ì½”ë„ˆë³„ ë‹¤ì‹œë³´ê¸°]   \n",
       "2  rc87JZwNqFA            [ë‹¨ë…] ë¡¯ë°ì¹´ë“œ í•´í‚¹ì—ì„œë„â€¦ì†Œë¦„ ë‹ëŠ” ê³µí†µì  ì°¾ì•˜ë‹¤ / SBS 8ë‰´ìŠ¤   \n",
       "3  7Pr_Vvn-4Og  [ë‹¨ë…] &quot;LG U+, KTë„ í„¸ë ¸ë‹¤â€¥&#39;í•´í‚¹ ì•„ëƒ&#39; ë²„í‹°ê¸°ì—...   \n",
       "4  GnYiq1DhdtI  [ë‹¨ë…] ë¡¯ë°ì¹´ë“œ, ë¶€ì •ì‚¬ìš© ì—†ë‹¤ë”ë‹ˆâ€¥2ì°¨ &#39;í”¼ì‹±&#39; ê³µê²© í™•ì¸ (20...   \n",
       "\n",
       "                                         description channelTitle  \\\n",
       "0  í•´í‚¹ì€ ì§€ë‚œë‹¬ 14ì¼ ì‹œì‘ëìŠµë‹ˆë‹¤. ì•…ì„±ì½”ë“œë¡œ ì˜¨ë¼ì¸ ê²°ì œ ì„œë²„ë¥¼ ëš«ì—ˆê³ , í•´ì»¤ë“¤ì€...     KBS News   \n",
       "1  ë§¤ë¶ˆì‡¼ #ìµœìš± #ë¡¯ë°ì¹´ë“œ #KT - ë³´ì•ˆ íŠ¹ì§‘ : ê¹€ìŠ¹ì£¼ X ì˜¤ìœ¤í˜œ --------...     [íŒŸë¹µ] ë§¤ë¶ˆì‡¼   \n",
       "2  ã€ˆì•µì»¤ã€‰ 297ë§Œ ëª…ì— ë‹¬í•˜ëŠ” ê°œì¸ì •ë³´ê°€ í„¸ë¦° ë¡¯ë°ì¹´ë“œ í•´í‚¹ ì‚¬íƒœê°€, ì¤‘êµ­ í•´í‚¹ ì¡°...       SBS ë‰´ìŠ¤   \n",
       "3  SKí…”ë ˆì½¤ì—ì„œ 2ì²œ3ë°±ë§Œ ê°€ì…ì ì •ë³´ê°€ ìœ ì¶œë¼, ìœ ì‹¬ ëŒ€ë€ì´ ë²Œì–´ì§„ ê²Œ ë„‰ ë‹¬ ì „ì´...      MBCNEWS   \n",
       "4  297ë§Œ ëª…ì˜ ê°œì¸ì •ë³´ê°€ ìœ ì¶œëœ ë¡¯ë°ì¹´ë“œ í•´í‚¹ ì‚¬íƒœì˜ íŒŒì¥ì´ í™•ì‚°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ìœ ...      MBCNEWS   \n",
       "\n",
       "                  channelId           publishedAt  \\\n",
       "0  UCcQTRi69dsVYHN3exePtZ1A  2025-09-19T01:35:02Z   \n",
       "1  UCMYhq9OyGI5UEz_NTAoHY7A  2025-09-22T11:42:16Z   \n",
       "2  UCkinYTS9IHqOEwR1Sze2JTw  2025-10-01T12:00:22Z   \n",
       "3  UCF4Wxdo3inmxP-Y59wXDsFw  2025-09-01T11:50:17Z   \n",
       "4  UCF4Wxdo3inmxP-Y59wXDsFw  2025-09-19T10:53:51Z   \n",
       "\n",
       "                                           url  viewCount  likeCount  \\\n",
       "0  https://www.youtube.com/watch?v=VaBG145v0UM     638378       3443   \n",
       "1  https://www.youtube.com/watch?v=4XwhXsUVHN0     302503       8080   \n",
       "2  https://www.youtube.com/watch?v=rc87JZwNqFA     285226       7523   \n",
       "3  https://www.youtube.com/watch?v=7Pr_Vvn-4Og     268457       3218   \n",
       "4  https://www.youtube.com/watch?v=GnYiq1DhdtI     211262       2180   \n",
       "\n",
       "   commentCount  subscriberCount  \\\n",
       "0           875          3480000   \n",
       "1           503          2830000   \n",
       "2          3774          5080000   \n",
       "3          1215          6040000   \n",
       "4           546          6040000   \n",
       "\n",
       "                                            text_raw gpt_post_sentiment  \\\n",
       "0  [ìë§‰ë‰´ìŠ¤] ë¡¯ë°ì¹´ë“œ ì“°ëŠ”ë°, &#39;ì´ ë¬¸ì&#39; ë°›ì•˜ë‹¤ë©´ ë‹¹ì¥ ì¹´ë“œ í•´ì§€í•˜...                 ë¶€ì •   \n",
       "1  ì¶©ê²©ì  ì‚¬ì‹¤! ì™¸êµ­ í•´ì»¤ì—ê²Œ ì™„ì „íˆ ëš«ë¦° í•œêµ­ì •ë¶€ê¸°ê´€! [ì½”ë„ˆë³„ ë‹¤ì‹œë³´ê¸°] ë§¤ë¶ˆì‡¼ ...                 ë¶€ì •   \n",
       "2  [ë‹¨ë…] ë¡¯ë°ì¹´ë“œ í•´í‚¹ì—ì„œë„â€¦ì†Œë¦„ ë‹ëŠ” ê³µí†µì  ì°¾ì•˜ë‹¤ / SBS 8ë‰´ìŠ¤ ã€ˆì•µì»¤ã€‰ 2...                 ë¶€ì •   \n",
       "3  [ë‹¨ë…] &quot;LG U+, KTë„ í„¸ë ¸ë‹¤â€¥&#39;í•´í‚¹ ì•„ëƒ&#39; ë²„í‹°ê¸°ì—...                 ë¶€ì •   \n",
       "4  [ë‹¨ë…] ë¡¯ë°ì¹´ë“œ, ë¶€ì •ì‚¬ìš© ì—†ë‹¤ë”ë‹ˆâ€¥2ì°¨ &#39;í”¼ì‹±&#39; ê³µê²© í™•ì¸ (20...                 ë¶€ì •   \n",
       "\n",
       "   gpt_post_confidence  \n",
       "0                 0.95  \n",
       "1                 0.92  \n",
       "2                 0.90  \n",
       "3                 0.91  \n",
       "4                 0.93  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ (Batch + JSON + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"ğŸ“Š GPT ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥(ê²Œì‹œê¸€ì˜ ì œëª©ê³¼ ì„¤ëª…)ì˜ ì „ì²´ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼\n",
    "        ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê²Œì‹œê¸€ì˜ ê°ì •ì„ í‰ê°€í•˜ëŠ” ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ê²Œì‹œê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ------------------------------------------------------------\n",
    "input_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\ë¡¯ë°ì¹´ë“œ_ì •ë³´ìœ ì¶œ_videos_20251103_165555.xlsx\"\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ ê²Œì‹œê¸€ í…ìŠ¤íŠ¸ ê²°í•© (ì œëª© + ì„¤ëª…)\n",
    "# ------------------------------------------------------------\n",
    "df[\"text_raw\"] = (\n",
    "    df.get(\"title\", \"\").astype(str).fillna(\"\") + \" \" + df.get(\"description\", \"\").astype(str).fillna(\"\")\n",
    ").str.strip().str[:500]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ (500ì)\n",
    "\n",
    "print(\"ì´ ê²Œì‹œê¸€ ìˆ˜:\", len(df))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"text_raw\"].tolist(), batch_size=20)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5ï¸âƒ£ ê²°ê³¼ ë°˜ì˜\n",
    "# ------------------------------------------------------------\n",
    "df[\"gpt_post_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_post_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6ï¸âƒ£ ê²°ê³¼ ì €ì¥\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\ë¡¯ë°ë°_posts_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ê²Œì‹œê¸€ ê°ì •ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì—¬ê¸°ë¶€í„° ë‹¤ì‹œí•˜ê¸° (11ì›” 7ì¼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 327/327 [59:45<00:00, 10.97s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\KT_ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>gpt_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F0UQQT0tSD8</td>\n",
       "      <td>@samelia-w1i</td>\n",
       "      <td>20 ë…„ì „ ëŒ€í¬í° ì‚¬ê±´ì„ ì‹œì‘ìœ¼ë¡œ í° ìœ¼ë¡œ ì¸í•œ ë²”ì£„ëŠ” ê°€ì¤‘ë ê²ƒì´ë‹¤</td>\n",
       "      <td>2025-10-22T10:37:31Z</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0UQQT0tSD8</td>\n",
       "      <td>@ì¢…í˜¸ë°•-g9c</td>\n",
       "      <td>2ì°¨ ì¸ì¦ìˆ˜ë‹¨ ë°”ê¿¨ì„ê±° ì•„ë‹ˆì—¬ ì§€ê¸ˆì¯¤ í”¼í•´ì ë” ì´ìƒ ì•ˆë‚˜ì˜¤ë©´ ì–´ëŠì •ë„ ë‹µë‚˜ì˜¨ê±° ì•„...</td>\n",
       "      <td>2025-10-07T16:45:57Z</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F0UQQT0tSD8</td>\n",
       "      <td>@í–‰ë³µì½”ë¦¬ì•„</td>\n",
       "      <td>ì¹´í†¡ìœ¼ë¡œë„ ê°€ë” ì£¼ë¯¼ë²ˆí˜¸ ë¬¼ì–´ë³´ëŠ” ì„¤ë¬¸ì§€ ëœ¨ê±°ë‚˜ ìˆ˜ìƒí•œ í”ì ì´ ê°€ë” ë– ì„œ ì˜ë¬¸ì´ ë“¤...</td>\n",
       "      <td>2025-10-02T00:39:27Z</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F0UQQT0tSD8</td>\n",
       "      <td>@ì´ì˜-z3g2h</td>\n",
       "      <td>êµ­ê°€ìœ„ê¸°ìƒí™© ì„ í¬í•˜ê³  ì¤‘êµ­ì¸ì…êµ­ê¸ˆì§€ì‹œí‚¤ì„¸ìš”</td>\n",
       "      <td>2025-09-30T13:40:06Z</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F0UQQT0tSD8</td>\n",
       "      <td>@12SU15</td>\n",
       "      <td>í•´í‚¹? ì ‘ì† ì•„ì´í”¼ê°€311ë¡œ ì‹œì‘ ë˜ë˜ë° 311ë¡œ ì‹œì‘í•˜ëŠ” ì•„ì´í”¼ëŠ” ìš°ë¦¬ë‚˜ë¼ ì•„ë‹ˆì§€...</td>\n",
       "      <td>2025-09-29T22:16:42Z</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId        author  \\\n",
       "0  F0UQQT0tSD8  @samelia-w1i   \n",
       "1  F0UQQT0tSD8      @ì¢…í˜¸ë°•-g9c   \n",
       "2  F0UQQT0tSD8        @í–‰ë³µì½”ë¦¬ì•„   \n",
       "3  F0UQQT0tSD8     @ì´ì˜-z3g2h   \n",
       "4  F0UQQT0tSD8       @12SU15   \n",
       "\n",
       "                                                text           publishedAt  \\\n",
       "0              20 ë…„ì „ ëŒ€í¬í° ì‚¬ê±´ì„ ì‹œì‘ìœ¼ë¡œ í° ìœ¼ë¡œ ì¸í•œ ë²”ì£„ëŠ” ê°€ì¤‘ë ê²ƒì´ë‹¤  2025-10-22T10:37:31Z   \n",
       "1  2ì°¨ ì¸ì¦ìˆ˜ë‹¨ ë°”ê¿¨ì„ê±° ì•„ë‹ˆì—¬ ì§€ê¸ˆì¯¤ í”¼í•´ì ë” ì´ìƒ ì•ˆë‚˜ì˜¤ë©´ ì–´ëŠì •ë„ ë‹µë‚˜ì˜¨ê±° ì•„...  2025-10-07T16:45:57Z   \n",
       "2  ì¹´í†¡ìœ¼ë¡œë„ ê°€ë” ì£¼ë¯¼ë²ˆí˜¸ ë¬¼ì–´ë³´ëŠ” ì„¤ë¬¸ì§€ ëœ¨ê±°ë‚˜ ìˆ˜ìƒí•œ í”ì ì´ ê°€ë” ë– ì„œ ì˜ë¬¸ì´ ë“¤...  2025-10-02T00:39:27Z   \n",
       "3                            êµ­ê°€ìœ„ê¸°ìƒí™© ì„ í¬í•˜ê³  ì¤‘êµ­ì¸ì…êµ­ê¸ˆì§€ì‹œí‚¤ì„¸ìš”  2025-09-30T13:40:06Z   \n",
       "4  í•´í‚¹? ì ‘ì† ì•„ì´í”¼ê°€311ë¡œ ì‹œì‘ ë˜ë˜ë° 311ë¡œ ì‹œì‘í•˜ëŠ” ì•„ì´í”¼ëŠ” ìš°ë¦¬ë‚˜ë¼ ì•„ë‹ˆì§€...  2025-09-29T22:16:42Z   \n",
       "\n",
       "  gpt_sentiment  gpt_confidence  \n",
       "0            ë¶€ì •            0.85  \n",
       "1            ë¶€ì •            0.78  \n",
       "2            ì¤‘ë¦½            0.60  \n",
       "3            ë¶€ì •            0.90  \n",
       "4            ì¤‘ë¦½            0.55  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê°ì •ë¶„ì„ ì´ˆê³ ì† ì•ˆì • ë²„ì „ (Batch + JSON ì¶œë ¥ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"GPT ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥ë“¤ì˜ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì •í™•íˆ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼ ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # âš¡ ì´ˆê³ ì† ëª¨ë¸\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬ ì¶”ê°€)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------------\n",
    "input_paths = [\n",
    "    r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\KT_í¨í† ì…€_í•´í‚¹_comments_20251103_152106.xlsx\",\n",
    "    # r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\SKT_ìœ ì‹¬ì¹©_ìœ ì¶œ_comments_20251103_165204.xlsx\",\n",
    "    # r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\KT_í¨í† ì…€_í•´í‚¹_comments_20251103_152106.xlsx\"\n",
    "]\n",
    "\n",
    "dfs = [pd.read_excel(path) for path in input_paths]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "if \"text\" not in df.columns:\n",
    "    raise ValueError(\"âš ï¸ ì…ë ¥ íŒŒì¼ì— 'text' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip().str[:300]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"text\"].tolist(), batch_size=20)\n",
    "\n",
    "df[\"gpt_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ (ì—‘ì…€)\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\YouTube_ê²°ê³¼\\KT_ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "# ìƒìœ„ 5í–‰ ë¯¸ë¦¬ë³´ê¸°\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë„¤ì´ë²„ ê°ì •ë¶„ì„ ì‹œì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [04:04<00:00,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\GS_ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>post_date</th>\n",
       "      <th>comment</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>gpt_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.03.25. 12:55</td>\n",
       "      <td>ê°œì†Œë¦¬ ë§ê³  ìš”ê¸°ìš”ë‚˜ ë‹¤ì‹œ íŒ”ì•„ë²„ë ¤ë¼</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/092/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.03.01. 13:32</td>\n",
       "      <td>ê°œì¸ì •ë³´ ìœ ì¶œì‹œí‚¤ëŠ” ì‚¬ëŒë“¤ì„ ë²•ì • ìµœê³ í˜• ìœ¼ë¡œ ë‹¤ìŠ¤ë ¤ì•¼ í•©ë‹ˆë‹¤.</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/092/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.03.01. 18:06</td>\n",
       "      <td>ì§€ë“¤ì´ í„¸ë ¤ë†“ê³  ê³ ê°íƒ“í•˜ê¸´</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/092/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.03.01. 20:55</td>\n",
       "      <td>ì ê²ŒëŠ” 5ê°œ ë§ê²ŒëŠ” ìˆ˜ì‹­ê°œì˜ ì‚¬ì´íŠ¸ ì•„ì´ë””ë‘ ë¹„ë²ˆì„ ì£¼ê¸°ì ìœ¼ë¡œ ì–¸ì œ ë‹¤ ë°”ê¾¸ëƒ......</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/092/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.03.01. 19:51</td>\n",
       "      <td>í•´í‚¹ ë‹¹í•œ ì—…ì²´ë“¤ì€ ê³¼ì§•ê¸ˆ í¬ê²Œ ë¨¹ì—¬ë¼! ë­” ë‚˜ë¼ê°€ í•´í‚¹ì— ì´ë¦¬ ì·¨ì•½í•˜ëƒ?</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel                                                url  title  \\\n",
       "0  naver_news  https://n.news.naver.com/mnews/article/003/001...    NaN   \n",
       "1  naver_news  https://n.news.naver.com/mnews/article/092/000...    NaN   \n",
       "2  naver_news  https://n.news.naver.com/mnews/article/092/000...    NaN   \n",
       "3  naver_news  https://n.news.naver.com/mnews/article/092/000...    NaN   \n",
       "4  naver_news  https://n.news.naver.com/mnews/article/092/000...    NaN   \n",
       "\n",
       "           post_date                                            comment  \\\n",
       "0  2025.03.25. 12:55                               ê°œì†Œë¦¬ ë§ê³  ìš”ê¸°ìš”ë‚˜ ë‹¤ì‹œ íŒ”ì•„ë²„ë ¤ë¼   \n",
       "1  2025.03.01. 13:32                ê°œì¸ì •ë³´ ìœ ì¶œì‹œí‚¤ëŠ” ì‚¬ëŒë“¤ì„ ë²•ì • ìµœê³ í˜• ìœ¼ë¡œ ë‹¤ìŠ¤ë ¤ì•¼ í•©ë‹ˆë‹¤.   \n",
       "2  2025.03.01. 18:06                                     ì§€ë“¤ì´ í„¸ë ¤ë†“ê³  ê³ ê°íƒ“í•˜ê¸´   \n",
       "3  2025.03.01. 20:55  ì ê²ŒëŠ” 5ê°œ ë§ê²ŒëŠ” ìˆ˜ì‹­ê°œì˜ ì‚¬ì´íŠ¸ ì•„ì´ë””ë‘ ë¹„ë²ˆì„ ì£¼ê¸°ì ìœ¼ë¡œ ì–¸ì œ ë‹¤ ë°”ê¾¸ëƒ......   \n",
       "4  2025.03.01. 19:51          í•´í‚¹ ë‹¹í•œ ì—…ì²´ë“¤ì€ ê³¼ì§•ê¸ˆ í¬ê²Œ ë¨¹ì—¬ë¼! ë­” ë‚˜ë¼ê°€ í•´í‚¹ì— ì´ë¦¬ ì·¨ì•½í•˜ëƒ?   \n",
       "\n",
       "  gpt_sentiment  gpt_confidence  \n",
       "0            ë¶€ì •            0.92  \n",
       "1            ê¸ì •            0.85  \n",
       "2            ë¶€ì •            0.88  \n",
       "3            ë¶€ì •            0.90  \n",
       "4            ë¶€ì •            0.91  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê°ì •ë¶„ì„ ì´ˆê³ ì† ì•ˆì • ë²„ì „ (Batch + JSON ì¶œë ¥ + ìºì‹± + ê¸¸ì´ë³´ì •)  >  naver ë‰´ìŠ¤ í™œìš© \n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"GPT ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥ë“¤ì˜ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì •í™•íˆ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼ ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # âš¡ ì´ˆê³ ì† ëª¨ë¸\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬ ì¶”ê°€)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------------\n",
    "input_paths = [\n",
    "    r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\GS_comments_2.csv\",\n",
    "\n",
    "]\n",
    "\n",
    "# íŒŒì¼ í™•ì¥ìë³„ë¡œ ìë™ íŒë³„í•´ì„œ ì½ê¸°\n",
    "dfs = [\n",
    "    pd.read_csv(path) if path.lower().endswith(\".csv\") else pd.read_excel(path)\n",
    "    for path in input_paths\n",
    "]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "if \"comment\" not in df.columns:\n",
    "    raise ValueError(\"âš ï¸ ì…ë ¥ íŒŒì¼ì— 'comment' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "df[\"comment\"] = df[\"comment\"].astype(str).str.strip().str[:300]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"comment\"].tolist(), batch_size=20)\n",
    "\n",
    "df[\"gpt_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ (ì—‘ì…€)\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\GS_ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "# ìƒìœ„ 5í–‰ ë¯¸ë¦¬ë³´ê¸°\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:42<00:00, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\GS_ë‰´ìŠ¤ê°ì •ë¶„ì„_GPT_labeled.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>í‚¤ì›Œë“œ</th>\n",
       "      <th>ì–¸ë¡ ì‚¬</th>\n",
       "      <th>ê²Œì‹œì¼</th>\n",
       "      <th>ë‰´ìŠ¤ì œëª©</th>\n",
       "      <th>url</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>gpt_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GS í•´í‚¹</td>\n",
       "      <td>ê²½í–¥ì‹ ë¬¸</td>\n",
       "      <td>2025-04-02 21:18:21</td>\n",
       "      <td>ë¹„ë²ˆ ì—†ì´ë„ í•´í‚¹Â·í”¼ì‹± ì°¨ë‹¨â€¦â€˜íŒ¨ìŠ¤í‚¤â€™ë¡œ ëˆˆëŒë¦¬ëŠ” ê¸°ì—…ë“¤</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/032/000...</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GS í•´í‚¹</td>\n",
       "      <td>ë‰´ìŠ¤1</td>\n",
       "      <td>2025-03-23 09:59:00</td>\n",
       "      <td>GSë¦¬í…Œì¼, 52g í™œë™ìœ¼ë¡œ ê³ ê°Â·í˜„ì¥ ì¤‘ì‹¬ ì¸ê³µì§€ëŠ¥ ì „í™˜ ì „ê°œ</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/421/000...</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GS í•´í‚¹</td>\n",
       "      <td>ì„œìš¸ê²½ì œ</td>\n",
       "      <td>2025-03-23 11:36:11</td>\n",
       "      <td>GSë¦¬í…Œì¼, ì¸ê³µì§€ëŠ¥ ì „í™˜ ë³¸ê²© ì „ê°œ</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/011/000...</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GS í•´í‚¹</td>\n",
       "      <td>ë§¤ì¼ì‹ ë¬¸</td>\n",
       "      <td>2025-03-23 13:24:16</td>\n",
       "      <td>\"ê³ ê° ë¶ˆí¸ AIë¡œ í•´ì†Œ\" GSë¦¬í…Œì¼, 'í˜„ì¥ ì¤‘ì‹¬ AX' ì„ ì–¸</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/088/000...</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GS í•´í‚¹</td>\n",
       "      <td>ë‰´ì‹œìŠ¤</td>\n",
       "      <td>2025-03-24 09:17:43</td>\n",
       "      <td>GSë¦¬í…Œì¼, 52g í™œë™ìœ¼ë¡œ ê³ ê°ê³¼ í˜„ì¥ ì¤‘ì‹¬ AI ì „í™˜ ë³¸ê²© ì „ê°œ</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     í‚¤ì›Œë“œ   ì–¸ë¡ ì‚¬                  ê²Œì‹œì¼                                   ë‰´ìŠ¤ì œëª©  \\\n",
       "0  GS í•´í‚¹  ê²½í–¥ì‹ ë¬¸  2025-04-02 21:18:21        ë¹„ë²ˆ ì—†ì´ë„ í•´í‚¹Â·í”¼ì‹± ì°¨ë‹¨â€¦â€˜íŒ¨ìŠ¤í‚¤â€™ë¡œ ëˆˆëŒë¦¬ëŠ” ê¸°ì—…ë“¤   \n",
       "1  GS í•´í‚¹   ë‰´ìŠ¤1  2025-03-23 09:59:00    GSë¦¬í…Œì¼, 52g í™œë™ìœ¼ë¡œ ê³ ê°Â·í˜„ì¥ ì¤‘ì‹¬ ì¸ê³µì§€ëŠ¥ ì „í™˜ ì „ê°œ   \n",
       "2  GS í•´í‚¹  ì„œìš¸ê²½ì œ  2025-03-23 11:36:11                   GSë¦¬í…Œì¼, ì¸ê³µì§€ëŠ¥ ì „í™˜ ë³¸ê²© ì „ê°œ   \n",
       "3  GS í•´í‚¹  ë§¤ì¼ì‹ ë¬¸  2025-03-23 13:24:16    \"ê³ ê° ë¶ˆí¸ AIë¡œ í•´ì†Œ\" GSë¦¬í…Œì¼, 'í˜„ì¥ ì¤‘ì‹¬ AX' ì„ ì–¸   \n",
       "4  GS í•´í‚¹   ë‰´ì‹œìŠ¤  2025-03-24 09:17:43  GSë¦¬í…Œì¼, 52g í™œë™ìœ¼ë¡œ ê³ ê°ê³¼ í˜„ì¥ ì¤‘ì‹¬ AI ì „í™˜ ë³¸ê²© ì „ê°œ   \n",
       "\n",
       "                                                 url gpt_sentiment  \\\n",
       "0  https://n.news.naver.com/mnews/article/032/000...            ì¤‘ë¦½   \n",
       "1  https://n.news.naver.com/mnews/article/421/000...            ê¸ì •   \n",
       "2  https://n.news.naver.com/mnews/article/011/000...            ê¸ì •   \n",
       "3  https://n.news.naver.com/mnews/article/088/000...            ê¸ì •   \n",
       "4  https://n.news.naver.com/mnews/article/003/001...            ê¸ì •   \n",
       "\n",
       "   gpt_confidence  \n",
       "0            0.65  \n",
       "1            0.70  \n",
       "2            0.75  \n",
       "3            0.80  \n",
       "4            0.75  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê°ì •ë¶„ì„ ì´ˆê³ ì† ì•ˆì • ë²„ì „ (Batch + JSON ì¶œë ¥ + ìºì‹± + ê¸¸ì´ë³´ì •)  >  naver ë‰´ìŠ¤ í™œìš© \n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"GPT ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥ë“¤ì˜ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì •í™•íˆ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼ ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # âš¡ ì´ˆê³ ì† ëª¨ë¸\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬ ì¶”ê°€)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------------\n",
    "input_paths = [\n",
    "    r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\GS_ë‰´ìŠ¤_20241223-20250406.csv\",\n",
    "\n",
    "]\n",
    "\n",
    "# íŒŒì¼ í™•ì¥ìë³„ë¡œ ìë™ íŒë³„í•´ì„œ ì½ê¸°\n",
    "dfs = [\n",
    "    pd.read_csv(path) if path.lower().endswith(\".csv\") else pd.read_excel(path)\n",
    "    for path in input_paths\n",
    "]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "if \"ë‰´ìŠ¤ì œëª©\" not in df.columns:\n",
    "    raise ValueError(\"âš ï¸ ì…ë ¥ íŒŒì¼ì— 'title' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "df[\"ë‰´ìŠ¤ì œëª©\"] = df[\"ë‰´ìŠ¤ì œëª©\"].astype(str).str.strip().str[:300]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"ë‰´ìŠ¤ì œëª©\"].tolist(), batch_size=20)\n",
    "\n",
    "df[\"gpt_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ (ì—‘ì…€)\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\GS_ë‰´ìŠ¤ê°ì •ë¶„ì„_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "# ìƒìœ„ 5í–‰ ë¯¸ë¦¬ë³´ê¸°\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [27:53<00:00, 14.81s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\KT_ëŒ“ê¸€ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>post_date</th>\n",
       "      <th>comment</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>gpt_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/032/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.10.28. 14:44</td>\n",
       "      <td>ì–´ì°¨í”¼ í„°ì§ˆì¼ ì•„ë‹ˆì—ˆë‚˜? KT ê°€ì…í•˜ë©´ ì—¬ê¸°ì €ê¸°ì„œ ë­ ê°€ì…í•´ë¼ ë­ ê°€ì…í•´ë¼ ì „í™”ì˜¤ëŠ”...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/032/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.10.28. 14:54</td>\n",
       "      <td>sktê°€ ê·¸ë‚˜ë§ˆ ë‚˜ì€ ê±° ì˜€ë„¤. 3ì‚¬ ë‹¤ í„¸ë¦¼</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/032/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.10.28. 14:30</td>\n",
       "      <td>ì§•ë²Œì  ì†í•´ë°°ìƒì ìš©ìœ¼ë¡œ ì •ë³´ìœ ì¶œëœ ê°œì¸ì—ê²Œ í”¼í•´ê¸ˆì•¡ì´ ì—†ë”ë¼ë„, 1ì¸ë‹¹ 10ë§Œì›ì”© ...</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/032/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.10.29. 08:56</td>\n",
       "      <td>ì€íë¥¼ í–ˆë‹¤ëŠ”ê²Œ ê°€ì¥í° ë¬¸ì œ ê°€ì…ì ìŠ¤ìŠ¤ë¡œ íŒë‹¨í• ìˆ˜ ìˆë„ë¡ ìœ„ì•½ê¸ˆ ì „ ê³ ê°ë©´ì œí•´ì•¼í•¨</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/032/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.10.28. 14:57</td>\n",
       "      <td>3ì‚¬ê°€ ë˜‘ ê°™ì€ ìƒí™©ì„.. ì •ë¶€ ê´€ë¦¬ë¶€ì‹¤ë¡œ ë°ì´íƒ€ ì„¼í„° í™”ì¬ ë‚œ ê²ƒì€ í”¼í•´ë³´ìƒ ì—†ëƒ ??</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel                                                url  title  \\\n",
       "0  naver_news  https://n.news.naver.com/mnews/article/032/000...    NaN   \n",
       "1  naver_news  https://n.news.naver.com/mnews/article/032/000...    NaN   \n",
       "2  naver_news  https://n.news.naver.com/mnews/article/032/000...    NaN   \n",
       "3  naver_news  https://n.news.naver.com/mnews/article/032/000...    NaN   \n",
       "4  naver_news  https://n.news.naver.com/mnews/article/032/000...    NaN   \n",
       "\n",
       "           post_date                                            comment  \\\n",
       "0  2025.10.28. 14:44  ì–´ì°¨í”¼ í„°ì§ˆì¼ ì•„ë‹ˆì—ˆë‚˜? KT ê°€ì…í•˜ë©´ ì—¬ê¸°ì €ê¸°ì„œ ë­ ê°€ì…í•´ë¼ ë­ ê°€ì…í•´ë¼ ì „í™”ì˜¤ëŠ”...   \n",
       "1  2025.10.28. 14:54                          sktê°€ ê·¸ë‚˜ë§ˆ ë‚˜ì€ ê±° ì˜€ë„¤. 3ì‚¬ ë‹¤ í„¸ë¦¼   \n",
       "2  2025.10.28. 14:30  ì§•ë²Œì  ì†í•´ë°°ìƒì ìš©ìœ¼ë¡œ ì •ë³´ìœ ì¶œëœ ê°œì¸ì—ê²Œ í”¼í•´ê¸ˆì•¡ì´ ì—†ë”ë¼ë„, 1ì¸ë‹¹ 10ë§Œì›ì”© ...   \n",
       "3  2025.10.29. 08:56     ì€íë¥¼ í–ˆë‹¤ëŠ”ê²Œ ê°€ì¥í° ë¬¸ì œ ê°€ì…ì ìŠ¤ìŠ¤ë¡œ íŒë‹¨í• ìˆ˜ ìˆë„ë¡ ìœ„ì•½ê¸ˆ ì „ ê³ ê°ë©´ì œí•´ì•¼í•¨   \n",
       "4  2025.10.28. 14:57  3ì‚¬ê°€ ë˜‘ ê°™ì€ ìƒí™©ì„.. ì •ë¶€ ê´€ë¦¬ë¶€ì‹¤ë¡œ ë°ì´íƒ€ ì„¼í„° í™”ì¬ ë‚œ ê²ƒì€ í”¼í•´ë³´ìƒ ì—†ëƒ ??   \n",
       "\n",
       "  gpt_sentiment  gpt_confidence  \n",
       "0            ë¶€ì •            0.95  \n",
       "1            ê¸ì •            0.80  \n",
       "2            ê¸ì •            0.85  \n",
       "3            ë¶€ì •            0.90  \n",
       "4            ë¶€ì •            0.88  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê°ì •ë¶„ì„ ì´ˆê³ ì† ì•ˆì • ë²„ì „ (Batch + JSON ì¶œë ¥ + ìºì‹± + ê¸¸ì´ë³´ì •)  >  naver ë‰´ìŠ¤ í™œìš© \n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"GPT ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥ë“¤ì˜ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì •í™•íˆ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼ ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # âš¡ ì´ˆê³ ì† ëª¨ë¸\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬ ì¶”ê°€)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------------\n",
    "input_paths = [\n",
    "    r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\KT_comments_2.csv\",\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "# íŒŒì¼ í™•ì¥ìë³„ë¡œ ìë™ íŒë³„í•´ì„œ ì½ê¸°\n",
    "dfs = [\n",
    "    pd.read_csv(path) if path.lower().endswith(\".csv\") else pd.read_excel(path)\n",
    "    for path in input_paths\n",
    "]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "if \"comment\" not in df.columns:\n",
    "    raise ValueError(\"âš ï¸ ì…ë ¥ íŒŒì¼ì— 'comment' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "df[\"comment\"] = df[\"comment\"].astype(str).str.strip().str[:300]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"comment\"].tolist(), batch_size=20)\n",
    "\n",
    "df[\"gpt_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ (ì—‘ì…€)\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\KT_ëŒ“ê¸€ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "# ìƒìœ„ 5í–‰ ë¯¸ë¦¬ë³´ê¸°\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:42<00:00, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\KT_ë‰´ìŠ¤ê°ì •ë¶„ì„_GPT_labeled.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>í‚¤ì›Œë“œ</th>\n",
       "      <th>ì–¸ë¡ ì‚¬</th>\n",
       "      <th>ê²Œì‹œì¼</th>\n",
       "      <th>ë‰´ìŠ¤ì œëª©</th>\n",
       "      <th>url</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>gpt_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KT í¨í† ì…€ í•´í‚¹</td>\n",
       "      <td>ì´ë°ì¼ë¦¬</td>\n",
       "      <td>2025-10-29 16:02:09</td>\n",
       "      <td>ê¹€ì˜ì„­ KT ëŒ€í‘œ â€œì „ì²´ ê³ ê° ìœ„ì•½ê¸ˆ ë©´ì œ, ì¢…í•© ê²€í† í•  ê²ƒâ€</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/018/000...</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KT í¨í† ì…€ í•´í‚¹</td>\n",
       "      <td>ë¸”ë¡œí„°</td>\n",
       "      <td>2025-10-29 17:36:14</td>\n",
       "      <td>KT ê¹€ì˜ì„­, êµ­ê°ì„œ ì—°ì„ ë„ì „ ì—¬ë¶€ ì§ˆë¬¸ì— \"ì´ì‚¬íšŒì„œ ì…ì¥ ë‚¼ ê²ƒ\"</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/293/000...</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KT í¨í† ì…€ í•´í‚¹</td>\n",
       "      <td>ì„œìš¸ê²½ì œ</td>\n",
       "      <td>2025-10-29 15:18:17</td>\n",
       "      <td>KT, ì†Œì•¡ê²°ì œ í”¼í•´ì ìœ„ì•½ê¸ˆ ë©´ì œâ€¦æœˆ 100GB ë¬´ë£Œ</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/011/000...</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KT í¨í† ì…€ í•´í‚¹</td>\n",
       "      <td>ë””ì§€í„¸íƒ€ì„ìŠ¤</td>\n",
       "      <td>2025-10-29 15:32:49</td>\n",
       "      <td>KT â€œì†Œì•¡ê²°ì œ í”¼í•´ ê³ ê°ì— 100GBÂ·15ë§Œì› ìš”ê¸ˆí• ì¸ ì œê³µâ€</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/029/000...</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KT í¨í† ì…€ í•´í‚¹</td>\n",
       "      <td>ê²½í–¥ì‹ ë¬¸</td>\n",
       "      <td>2025-10-28 14:04:00</td>\n",
       "      <td>KT ì´ìš©ì 10ëª… ì¤‘ 8ëª… â€œì „ ê³ ê° ëŒ€ìƒ ìœ„ì•½ê¸ˆ ë©´ì œí•´ì•¼â€</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/032/000...</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         í‚¤ì›Œë“œ     ì–¸ë¡ ì‚¬                  ê²Œì‹œì¼  \\\n",
       "0  KT í¨í† ì…€ í•´í‚¹    ì´ë°ì¼ë¦¬  2025-10-29 16:02:09   \n",
       "1  KT í¨í† ì…€ í•´í‚¹     ë¸”ë¡œí„°  2025-10-29 17:36:14   \n",
       "2  KT í¨í† ì…€ í•´í‚¹    ì„œìš¸ê²½ì œ  2025-10-29 15:18:17   \n",
       "3  KT í¨í† ì…€ í•´í‚¹  ë””ì§€í„¸íƒ€ì„ìŠ¤  2025-10-29 15:32:49   \n",
       "4  KT í¨í† ì…€ í•´í‚¹    ê²½í–¥ì‹ ë¬¸  2025-10-28 14:04:00   \n",
       "\n",
       "                                     ë‰´ìŠ¤ì œëª©  \\\n",
       "0      ê¹€ì˜ì„­ KT ëŒ€í‘œ â€œì „ì²´ ê³ ê° ìœ„ì•½ê¸ˆ ë©´ì œ, ì¢…í•© ê²€í† í•  ê²ƒâ€   \n",
       "1  KT ê¹€ì˜ì„­, êµ­ê°ì„œ ì—°ì„ ë„ì „ ì—¬ë¶€ ì§ˆë¬¸ì— \"ì´ì‚¬íšŒì„œ ì…ì¥ ë‚¼ ê²ƒ\"   \n",
       "2          KT, ì†Œì•¡ê²°ì œ í”¼í•´ì ìœ„ì•½ê¸ˆ ë©´ì œâ€¦æœˆ 100GB ë¬´ë£Œ   \n",
       "3     KT â€œì†Œì•¡ê²°ì œ í”¼í•´ ê³ ê°ì— 100GBÂ·15ë§Œì› ìš”ê¸ˆí• ì¸ ì œê³µâ€   \n",
       "4      KT ì´ìš©ì 10ëª… ì¤‘ 8ëª… â€œì „ ê³ ê° ëŒ€ìƒ ìœ„ì•½ê¸ˆ ë©´ì œí•´ì•¼â€   \n",
       "\n",
       "                                                 url gpt_sentiment  \\\n",
       "0  https://n.news.naver.com/mnews/article/018/000...            ì¤‘ë¦½   \n",
       "1  https://n.news.naver.com/mnews/article/293/000...            ì¤‘ë¦½   \n",
       "2  https://n.news.naver.com/mnews/article/011/000...            ê¸ì •   \n",
       "3  https://n.news.naver.com/mnews/article/029/000...            ê¸ì •   \n",
       "4  https://n.news.naver.com/mnews/article/032/000...            ê¸ì •   \n",
       "\n",
       "   gpt_confidence  \n",
       "0            0.65  \n",
       "1            0.60  \n",
       "2            0.85  \n",
       "3            0.80  \n",
       "4            0.75  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê°ì •ë¶„ì„ ì´ˆê³ ì† ì•ˆì • ë²„ì „ (Batch + JSON ì¶œë ¥ + ìºì‹± + ê¸¸ì´ë³´ì •)  >  naver ë‰´ìŠ¤ í™œìš© \n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"GPT ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥ë“¤ì˜ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì •í™•íˆ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼ ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # âš¡ ì´ˆê³ ì† ëª¨ë¸\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬ ì¶”ê°€)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------------\n",
    "input_paths = [\n",
    "    r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\KT_ë‰´ìŠ¤_20250901-20251031.csv\",\n",
    "\n",
    "]\n",
    "\n",
    "# íŒŒì¼ í™•ì¥ìë³„ë¡œ ìë™ íŒë³„í•´ì„œ ì½ê¸°\n",
    "dfs = [\n",
    "    pd.read_csv(path) if path.lower().endswith(\".csv\") else pd.read_excel(path)\n",
    "    for path in input_paths\n",
    "]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "if \"ë‰´ìŠ¤ì œëª©\" not in df.columns:\n",
    "    raise ValueError(\"âš ï¸ ì…ë ¥ íŒŒì¼ì— 'comment' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "df[\"ë‰´ìŠ¤ì œëª©\"] = df[\"ë‰´ìŠ¤ì œëª©\"].astype(str).str.strip().str[:300]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"ë‰´ìŠ¤ì œëª©\"].tolist(), batch_size=20)\n",
    "\n",
    "df[\"gpt_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ (ì—‘ì…€)\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\KT_ë‰´ìŠ¤ê°ì •ë¶„ì„_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "# ìƒìœ„ 5í–‰ ë¯¸ë¦¬ë³´ê¸°\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [15:37<00:00,  8.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\ë¡¯ë°_ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>post_date</th>\n",
       "      <th>comment</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>gpt_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/079/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.10.13. 13:50</td>\n",
       "      <td>ì¥ë‚œì¹˜ë‚˜. ì£¼ë¯¼ë²ˆí˜¸ê¹Œì§€ í„¸ë ¸ëŠ”ë°, ë³´í˜¸ì¡°ì¹˜ ê°™ì€ ì†Œë¦¬í•˜ê³  ìˆë„¤. ì–´ë”” ì†Œì†¡í•˜ëŠ” ê³³ ì—†ë‚˜?</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/366/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.10.14. 17:55</td>\n",
       "      <td>í´ë¦°ë´‡ì´ ë¶€ì ì ˆí•œ í‘œí˜„ì„ ê°ì§€í•œ ëŒ“ê¸€ì…ë‹ˆë‹¤.</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/586/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.10.13. 12:42</td>\n",
       "      <td>ì ‘ëŒ€ 11ë²ˆ ë°›ìœ¼ëŸ¬ ê°„ê±°ë„¤ ê¸°ì—… ìœ í¥ ë²•ì¹´ì˜ ì›í‰</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.10.14. 15:08</td>\n",
       "      <td>êµ­ê°œì˜ì›ë„˜ì•„ ê²€ì‚¬ë¥¼ í–ˆë˜ ê¸ˆê°ì›í•œí…Œ ë­ë¼í•´ì•¼ì§€ ë§ëŒ€ë¡œ ê±”ë„¤ê°€ ê²€ì‚¬ë¥¼ ì†Œí™€ì´ í•œê±°ì–ì•„</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.10.16. 11:33</td>\n",
       "      <td>ì‹¬ì‚¬ê¸°ê°„ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ í˜„ì¥ ì ê²€í•  ì‹œê°„ì´ ê±°ì˜ ì—†ë‹¤ê³  ë³´ë©´ ë©ë‹ˆë‹¤. ì„œ...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel                                                url  title  \\\n",
       "0  naver_news  https://n.news.naver.com/mnews/article/079/000...    NaN   \n",
       "1  naver_news  https://n.news.naver.com/mnews/article/366/000...    NaN   \n",
       "2  naver_news  https://n.news.naver.com/mnews/article/586/000...    NaN   \n",
       "3  naver_news  https://n.news.naver.com/mnews/article/003/001...    NaN   \n",
       "4  naver_news  https://n.news.naver.com/mnews/article/003/001...    NaN   \n",
       "\n",
       "           post_date                                            comment  \\\n",
       "0  2025.10.13. 13:50  ì¥ë‚œì¹˜ë‚˜. ì£¼ë¯¼ë²ˆí˜¸ê¹Œì§€ í„¸ë ¸ëŠ”ë°, ë³´í˜¸ì¡°ì¹˜ ê°™ì€ ì†Œë¦¬í•˜ê³  ìˆë„¤. ì–´ë”” ì†Œì†¡í•˜ëŠ” ê³³ ì—†ë‚˜?   \n",
       "1  2025.10.14. 17:55                           í´ë¦°ë´‡ì´ ë¶€ì ì ˆí•œ í‘œí˜„ì„ ê°ì§€í•œ ëŒ“ê¸€ì…ë‹ˆë‹¤.   \n",
       "2  2025.10.13. 12:42                        ì ‘ëŒ€ 11ë²ˆ ë°›ìœ¼ëŸ¬ ê°„ê±°ë„¤ ê¸°ì—… ìœ í¥ ë²•ì¹´ì˜ ì›í‰   \n",
       "3  2025.10.14. 15:08     êµ­ê°œì˜ì›ë„˜ì•„ ê²€ì‚¬ë¥¼ í–ˆë˜ ê¸ˆê°ì›í•œí…Œ ë­ë¼í•´ì•¼ì§€ ë§ëŒ€ë¡œ ê±”ë„¤ê°€ ê²€ì‚¬ë¥¼ ì†Œí™€ì´ í•œê±°ì–ì•„   \n",
       "4  2025.10.16. 11:33  ì‹¬ì‚¬ê¸°ê°„ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ í˜„ì¥ ì ê²€í•  ì‹œê°„ì´ ê±°ì˜ ì—†ë‹¤ê³  ë³´ë©´ ë©ë‹ˆë‹¤. ì„œ...   \n",
       "\n",
       "  gpt_sentiment  gpt_confidence  \n",
       "0            ë¶€ì •            0.95  \n",
       "1            ì¤‘ë¦½            0.60  \n",
       "2            ë¶€ì •            0.90  \n",
       "3            ë¶€ì •            0.92  \n",
       "4            ë¶€ì •            0.85  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê°ì •ë¶„ì„ ì´ˆê³ ì† ì•ˆì • ë²„ì „ (Batch + JSON ì¶œë ¥ + ìºì‹± + ê¸¸ì´ë³´ì •)  >  naver ë‰´ìŠ¤ í™œìš© \n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"GPT ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥ë“¤ì˜ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì •í™•íˆ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼ ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # âš¡ ì´ˆê³ ì† ëª¨ë¸\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬ ì¶”ê°€)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------------\n",
    "input_paths = [\n",
    "    r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\lotte_comments_2.csv\",\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "# íŒŒì¼ í™•ì¥ìë³„ë¡œ ìë™ íŒë³„í•´ì„œ ì½ê¸°\n",
    "dfs = [\n",
    "    pd.read_csv(path) if path.lower().endswith(\".csv\") else pd.read_excel(path)\n",
    "    for path in input_paths\n",
    "]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "if \"comment\" not in df.columns:\n",
    "    raise ValueError(\"âš ï¸ ì…ë ¥ íŒŒì¼ì— 'comment' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "df[\"comment\"] = df[\"comment\"].astype(str).str.strip().str[:300]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"comment\"].tolist(), batch_size=20)\n",
    "\n",
    "df[\"gpt_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ (ì—‘ì…€)\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\ë¡¯ë°_ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "# ìƒìœ„ 5í–‰ ë¯¸ë¦¬ë³´ê¸°\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [02:42<00:00,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\ë¡¯ë°_ë‰´ìŠ¤ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>í‚¤ì›Œë“œ</th>\n",
       "      <th>ì–¸ë¡ ì‚¬</th>\n",
       "      <th>ê²Œì‹œì¼</th>\n",
       "      <th>ë‰´ìŠ¤ì œëª©</th>\n",
       "      <th>url</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>gpt_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë¡¯ë° ì •ë³´ìœ ì¶œ</td>\n",
       "      <td>ë¯¸ë””ì–´ì˜¤ëŠ˜</td>\n",
       "      <td>2025-10-16 21:05:09</td>\n",
       "      <td>ê°œì¸ì •ë³´ìœ„ì›íšŒ ìˆ˜ì¥ì— AI ì „ë¬¸ê°€ ì„ëª…â€¦ì‹œë¯¼ì‚¬íšŒ ìš°ë ¤</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/006/000...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë¡¯ë° ì •ë³´ìœ ì¶œ</td>\n",
       "      <td>ì—°í•©ë‰´ìŠ¤</td>\n",
       "      <td>2025-10-16 09:14:01</td>\n",
       "      <td>KTÂ·ë¡¯ë°ì¹´ë“œ í•´í‚¹ ì‚¬íƒœì¸ë°â€¦KISA, ì œì£¼ ì›Œí¬ìˆ ë…¼ë€</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/001/001...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë¡¯ë° ì •ë³´ìœ ì¶œ</td>\n",
       "      <td>ì¡°ì„ ë¹„ì¦ˆ</td>\n",
       "      <td>2025-10-16 12:44:14</td>\n",
       "      <td>â€œKTÂ·ë¡¯ë°ì¹´ë“œ í•´í‚¹ ì‚¬íƒœ ì§„í–‰ ì¤‘ì¸ë°â€â€¦ KISA, ì œì£¼ ì›Œí¬ìˆ ê°•í–‰ ë…¼ë€</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/366/000...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë¡¯ë° ì •ë³´ìœ ì¶œ</td>\n",
       "      <td>MBC</td>\n",
       "      <td>2025-10-13 11:38:15</td>\n",
       "      <td>ë¡¯ë°ì¹´ë“œ í•´í‚¹ ë‘ ë‹¬ì§¸, íšŒì› íƒˆí‡´ 3ë§Œ ëª…Â·ì¹´ë“œ í•´ì§€ 5ë§Œ ëª…</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/214/000...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ë¡¯ë° ì •ë³´ìœ ì¶œ</td>\n",
       "      <td>ë…¸ì»·ë‰´ìŠ¤</td>\n",
       "      <td>2025-10-13 13:00:11</td>\n",
       "      <td>ë¡¯ë°ì¹´ë“œ \"ë¯¼ê°ì •ë³´ ìœ ì¶œ ê³ ê° 82% ë³´í˜¸ì¡°ì¹˜ ì™„ë£Œ\"</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/079/000...</td>\n",
       "      <td>ê¸ì •</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       í‚¤ì›Œë“œ    ì–¸ë¡ ì‚¬                  ê²Œì‹œì¼  \\\n",
       "0  ë¡¯ë° ì •ë³´ìœ ì¶œ  ë¯¸ë””ì–´ì˜¤ëŠ˜  2025-10-16 21:05:09   \n",
       "1  ë¡¯ë° ì •ë³´ìœ ì¶œ   ì—°í•©ë‰´ìŠ¤  2025-10-16 09:14:01   \n",
       "2  ë¡¯ë° ì •ë³´ìœ ì¶œ   ì¡°ì„ ë¹„ì¦ˆ  2025-10-16 12:44:14   \n",
       "3  ë¡¯ë° ì •ë³´ìœ ì¶œ    MBC  2025-10-13 11:38:15   \n",
       "4  ë¡¯ë° ì •ë³´ìœ ì¶œ   ë…¸ì»·ë‰´ìŠ¤  2025-10-13 13:00:11   \n",
       "\n",
       "                                         ë‰´ìŠ¤ì œëª©  \\\n",
       "0               ê°œì¸ì •ë³´ìœ„ì›íšŒ ìˆ˜ì¥ì— AI ì „ë¬¸ê°€ ì„ëª…â€¦ì‹œë¯¼ì‚¬íšŒ ìš°ë ¤   \n",
       "1             KTÂ·ë¡¯ë°ì¹´ë“œ í•´í‚¹ ì‚¬íƒœì¸ë°â€¦KISA, ì œì£¼ ì›Œí¬ìˆ ë…¼ë€   \n",
       "2  â€œKTÂ·ë¡¯ë°ì¹´ë“œ í•´í‚¹ ì‚¬íƒœ ì§„í–‰ ì¤‘ì¸ë°â€â€¦ KISA, ì œì£¼ ì›Œí¬ìˆ ê°•í–‰ ë…¼ë€   \n",
       "3         ë¡¯ë°ì¹´ë“œ í•´í‚¹ ë‘ ë‹¬ì§¸, íšŒì› íƒˆí‡´ 3ë§Œ ëª…Â·ì¹´ë“œ í•´ì§€ 5ë§Œ ëª…   \n",
       "4               ë¡¯ë°ì¹´ë“œ \"ë¯¼ê°ì •ë³´ ìœ ì¶œ ê³ ê° 82% ë³´í˜¸ì¡°ì¹˜ ì™„ë£Œ\"   \n",
       "\n",
       "                                                 url gpt_sentiment  \\\n",
       "0  https://n.news.naver.com/mnews/article/006/000...            ë¶€ì •   \n",
       "1  https://n.news.naver.com/mnews/article/001/001...            ë¶€ì •   \n",
       "2  https://n.news.naver.com/mnews/article/366/000...            ë¶€ì •   \n",
       "3  https://n.news.naver.com/mnews/article/214/000...            ë¶€ì •   \n",
       "4  https://n.news.naver.com/mnews/article/079/000...            ê¸ì •   \n",
       "\n",
       "   gpt_confidence  \n",
       "0            0.85  \n",
       "1            0.88  \n",
       "2            0.87  \n",
       "3            0.90  \n",
       "4            0.75  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê°ì •ë¶„ì„ ì´ˆê³ ì† ì•ˆì • ë²„ì „ (Batch + JSON ì¶œë ¥ + ìºì‹± + ê¸¸ì´ë³´ì •)  >  naver ë‰´ìŠ¤ í™œìš© \n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"GPT ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥ë“¤ì˜ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì •í™•íˆ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼ ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # âš¡ ì´ˆê³ ì† ëª¨ë¸\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬ ì¶”ê°€)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------------\n",
    "input_paths = [\n",
    "    r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\ë¡¯ë°ì¹´ë“œ_ë‰´ìŠ¤_20250819-20251016.csv\",\n",
    " \n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "# íŒŒì¼ í™•ì¥ìë³„ë¡œ ìë™ íŒë³„í•´ì„œ ì½ê¸°\n",
    "dfs = [\n",
    "    pd.read_csv(path) if path.lower().endswith(\".csv\") else pd.read_excel(path)\n",
    "    for path in input_paths\n",
    "]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "if \"ë‰´ìŠ¤ì œëª©\" not in df.columns:\n",
    "    raise ValueError(\"âš ï¸ ì…ë ¥ íŒŒì¼ì— 'comment' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "df[\"ë‰´ìŠ¤ì œëª©\"] = df[\"ë‰´ìŠ¤ì œëª©\"].astype(str).str.strip().str[:300]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"ë‰´ìŠ¤ì œëª©\"].tolist(), batch_size=20)\n",
    "\n",
    "df[\"gpt_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ (ì—‘ì…€)\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\ë¡¯ë°_ë‰´ìŠ¤ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "# ìƒìœ„ 5í–‰ ë¯¸ë¦¬ë³´ê¸°\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [1:48:16<00:00,  8.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\SKT_ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>post_date</th>\n",
       "      <th>comment</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>gpt_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/417/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.05.30. 21:38</td>\n",
       "      <td>ë‚œ ì™œ ì•ˆë°”ê¿”ì£¼ëƒ</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/417/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.05.31. 01:24</td>\n",
       "      <td>ë‹¤ìŒë‹¬ì¯¤ ìœ ì‹¬ ë°”ê¾¸ê³  ë²ˆí˜¸ì´ë™í•´ì•¼ì§€</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/417/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.05.30. 21:34</td>\n",
       "      <td>ë‚œ ì•„ì§</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/417/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.05.30. 21:29</td>\n",
       "      <td>ê¸°ì—…ì´ë¯¸ì§€ ì´ë¯¸ ìƒì‹¤ë¨ ê¸°ì§€êµ­ë³€ê²½ í˜„ì‹¤í™”</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naver_news</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/417/000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025.05.30. 15:18</td>\n",
       "      <td>ì•„ì§ë„ ê·¸íšŒì‚¬ë¥¼ ì™œì“°ëŠ”ê±°ì§€?</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel                                                url  title  \\\n",
       "0  naver_news  https://n.news.naver.com/mnews/article/417/000...    NaN   \n",
       "1  naver_news  https://n.news.naver.com/mnews/article/417/000...    NaN   \n",
       "2  naver_news  https://n.news.naver.com/mnews/article/417/000...    NaN   \n",
       "3  naver_news  https://n.news.naver.com/mnews/article/417/000...    NaN   \n",
       "4  naver_news  https://n.news.naver.com/mnews/article/417/000...    NaN   \n",
       "\n",
       "           post_date                 comment gpt_sentiment  gpt_confidence  \n",
       "0  2025.05.30. 21:38               ë‚œ ì™œ ì•ˆë°”ê¿”ì£¼ëƒ            ë¶€ì •            0.85  \n",
       "1  2025.05.31. 01:24     ë‹¤ìŒë‹¬ì¯¤ ìœ ì‹¬ ë°”ê¾¸ê³  ë²ˆí˜¸ì´ë™í•´ì•¼ì§€            ì¤‘ë¦½            0.60  \n",
       "2  2025.05.30. 21:34                    ë‚œ ì•„ì§            ì¤‘ë¦½            0.50  \n",
       "3  2025.05.30. 21:29  ê¸°ì—…ì´ë¯¸ì§€ ì´ë¯¸ ìƒì‹¤ë¨ ê¸°ì§€êµ­ë³€ê²½ í˜„ì‹¤í™”            ë¶€ì •            0.90  \n",
       "4  2025.05.30. 15:18         ì•„ì§ë„ ê·¸íšŒì‚¬ë¥¼ ì™œì“°ëŠ”ê±°ì§€?            ë¶€ì •            0.88  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê°ì •ë¶„ì„ ì´ˆê³ ì† ì•ˆì • ë²„ì „ (Batch + JSON ì¶œë ¥ + ìºì‹± + ê¸¸ì´ë³´ì •)  >  naver ë‰´ìŠ¤ í™œìš© \n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re, os\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë¬¸ì¥ì„ batch ë‹¨ìœ„ë¡œ GPTì— ì „ë‹¬í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    ì¤‘ë³µ ë¬¸ì¥ì€ ìºì‹œ(cache)ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"GPT ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # âœ… 1. ìºì‹œì— ì—†ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        # âœ… 2. ëª¨ë‘ ìºì‹œì— ìˆë‹¤ë©´ ë°”ë¡œ append\n",
    "        if not new_texts:\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "            continue\n",
    "\n",
    "        # âœ… 3. GPT í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ê°•ì œ)\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥ë“¤ì˜ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì •í™•íˆ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼ ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # âš¡ ì´ˆê³ ì† ëª¨ë¸\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # âœ… 4. JSON íŒŒì‹± ì‹œë„\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë°±ì—… íŒŒì„œë¡œ ì¬ì‹œë„\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            # âœ… 5. batch_results ê¸¸ì´ ë³´ì • (í•µì‹¬ ì¶”ê°€)\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                batch_results = (batch_results + \n",
    "                                 [{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0}] * (len(new_texts) - len(batch_results)))[:len(new_texts)]\n",
    "\n",
    "            # âœ… 6. ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            # âœ… 7. ì „ì²´ ê²°ê³¼ ë³‘í•©\n",
    "            for t in batch:\n",
    "                results.append(cache[t])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            for t in batch:\n",
    "                results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------------\n",
    "input_paths = [\n",
    "    r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\SKT_comments_2.csv\",\n",
    "]\n",
    "\n",
    "# íŒŒì¼ í™•ì¥ìë³„ë¡œ ìë™ íŒë³„í•´ì„œ ì½ê¸°\n",
    "dfs = []\n",
    "for path in input_paths:\n",
    "    path = path.strip()\n",
    "    # íŒŒì¼ì´ csvì¸ì§€ xlsx/xls ì¸ì§€ íŒë‹¨\n",
    "    _, ext = os.path.splitext(path)\n",
    "    ext = ext.lower()\n",
    "    if ext == \".csv\":\n",
    "        dfs.append(pd.read_csv(path, encoding=\"utf-8\"))\n",
    "    elif ext in [\".xlsx\", \".xls\"]:\n",
    "        # ì—‘ì…€ íŒŒì¼ì€ openpyxl ì—”ì§„ ì§€ì •\n",
    "        dfs.append(pd.read_excel(path, engine=\"openpyxl\"))\n",
    "    else:\n",
    "        raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {ext}\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "if \"comment\" not in df.columns:\n",
    "    raise ValueError(\"âš ï¸ ì…ë ¥ íŒŒì¼ì— 'comment' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "df[\"comment\"] = df[\"comment\"].astype(str).str.strip().str[:300]  # ê³¼ë„í•œ ê¸¸ì´ ì œí•œ\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"comment\"].tolist(), batch_size=20)\n",
    "\n",
    "df[\"gpt_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ (ì—‘ì…€)\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\SKT_ëŒ“ê¸€ê°ì •ë¶„ì„_GPT_labeled.xlsx\"\n",
    "# ì—‘ì…€ ì €ì¥ ì‹œ openpyxl ì—”ì§„ ì§€ì •\n",
    "df.to_excel(output_path, index=False, engine=\"openpyxl\")\n",
    "print(f\"\\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "\n",
    "# ìƒìœ„ 5í–‰ ë¯¸ë¦¬ë³´ê¸°\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT ê°ì •ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [07:15<00:00,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\n",
      "ğŸ“‚ C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\SKT_ë‰´ìŠ¤ê°ì •ë¶„ì„_GPT_labeled.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>í‚¤ì›Œë“œ</th>\n",
       "      <th>ì–¸ë¡ ì‚¬</th>\n",
       "      <th>ê²Œì‹œì¼</th>\n",
       "      <th>ë‰´ìŠ¤ì œëª©</th>\n",
       "      <th>url</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>gpt_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SK ìœ ì‹¬ í•´í‚¹</td>\n",
       "      <td>ë¨¸ë‹ˆS</td>\n",
       "      <td>2025-05-30 14:58:14</td>\n",
       "      <td>ìœ ì‹¬ êµì²´ SKí…”ë ˆì½¤ ê³ ê° 537ë§Œëª…â€¦ ëŒ€ê¸°ëŠ” 372ë§Œëª…</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/417/000...</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SK ìœ ì‹¬ í•´í‚¹</td>\n",
       "      <td>ë‰´ì‹œìŠ¤</td>\n",
       "      <td>2025-05-30 11:01:52</td>\n",
       "      <td>SKT, ê°€ì…ì 537ë§Œëª… 'ìœ ì‹¬ êµì²´'â€¦ì˜ˆì•½ì 372ë§Œëª… ë‚¨ì•„</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SK ìœ ì‹¬ í•´í‚¹</td>\n",
       "      <td>ì´ë°ì¼ë¦¬</td>\n",
       "      <td>2025-05-30 12:16:21</td>\n",
       "      <td>SKí…”ë ˆì½¤, ìœ ì‹¬êµì²´ 537ë§Œê±´â€¦ì˜ˆì•½ëŒ€ê¸° 372ë§Œëª…</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/018/000...</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SK ìœ ì‹¬ í•´í‚¹</td>\n",
       "      <td>ë¶€ì‚°ì¼ë³´</td>\n",
       "      <td>2025-05-30 14:58:13</td>\n",
       "      <td>SKT â€œê°€ì…ì 537ë§Œ ëª… ìœ ì‹¬ êµì²´â€â€¦ì”ì—¬ ì˜ˆì•½ì 372ë§Œ ëª…</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/082/000...</td>\n",
       "      <td>ì¤‘ë¦½</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SK ìœ ì‹¬ í•´í‚¹</td>\n",
       "      <td>ë‰´ì‹œìŠ¤</td>\n",
       "      <td>2025-05-30 06:00:00</td>\n",
       "      <td>SKT 40% ì ìœ ìœ¨ ë¶•ê´´ ì´ˆì½ê¸°â€¦ê°€ì…ì 40ë§Œ ìƒì—ˆë‹¤</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        í‚¤ì›Œë“œ   ì–¸ë¡ ì‚¬                  ê²Œì‹œì¼                                  ë‰´ìŠ¤ì œëª©  \\\n",
       "0  SK ìœ ì‹¬ í•´í‚¹   ë¨¸ë‹ˆS  2025-05-30 14:58:14       ìœ ì‹¬ êµì²´ SKí…”ë ˆì½¤ ê³ ê° 537ë§Œëª…â€¦ ëŒ€ê¸°ëŠ” 372ë§Œëª…   \n",
       "1  SK ìœ ì‹¬ í•´í‚¹   ë‰´ì‹œìŠ¤  2025-05-30 11:01:52   SKT, ê°€ì…ì 537ë§Œëª… 'ìœ ì‹¬ êµì²´'â€¦ì˜ˆì•½ì 372ë§Œëª… ë‚¨ì•„   \n",
       "2  SK ìœ ì‹¬ í•´í‚¹  ì´ë°ì¼ë¦¬  2025-05-30 12:16:21          SKí…”ë ˆì½¤, ìœ ì‹¬êµì²´ 537ë§Œê±´â€¦ì˜ˆì•½ëŒ€ê¸° 372ë§Œëª…   \n",
       "3  SK ìœ ì‹¬ í•´í‚¹  ë¶€ì‚°ì¼ë³´  2025-05-30 14:58:13  SKT â€œê°€ì…ì 537ë§Œ ëª… ìœ ì‹¬ êµì²´â€â€¦ì”ì—¬ ì˜ˆì•½ì 372ë§Œ ëª…   \n",
       "4  SK ìœ ì‹¬ í•´í‚¹   ë‰´ì‹œìŠ¤  2025-05-30 06:00:00        SKT 40% ì ìœ ìœ¨ ë¶•ê´´ ì´ˆì½ê¸°â€¦ê°€ì…ì 40ë§Œ ìƒì—ˆë‹¤   \n",
       "\n",
       "                                                 url gpt_sentiment  \\\n",
       "0  https://n.news.naver.com/mnews/article/417/000...            ì¤‘ë¦½   \n",
       "1  https://n.news.naver.com/mnews/article/003/001...            ì¤‘ë¦½   \n",
       "2  https://n.news.naver.com/mnews/article/018/000...            ì¤‘ë¦½   \n",
       "3  https://n.news.naver.com/mnews/article/082/000...            ì¤‘ë¦½   \n",
       "4  https://n.news.naver.com/mnews/article/003/001...            ë¶€ì •   \n",
       "\n",
       "   gpt_confidence  \n",
       "0            0.85  \n",
       "1            0.85  \n",
       "2            0.85  \n",
       "3            0.85  \n",
       "4            0.92  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# âœ… GPT ê°ì •ë¶„ì„ ì´ˆê³ ì† ì•ˆì • ë²„ì „ (Batch + JSON ì¶œë ¥ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "#    - Naver ë‰´ìŠ¤ ê°ì • ë¶„ì„ìš©\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import json, time, re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "client = OpenAI(api_key=api_key)",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ GPT ê°ì •ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ + ìºì‹± + ê¸¸ì´ë³´ì •)\n",
    "# ------------------------------------------------------------\n",
    "cache = {}\n",
    "\n",
    "def gpt_batch_sentiment(texts, batch_size=20, sleep_sec=0.5):\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"GPT ê°ì •ë¶„ì„ ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        new_texts = [t for t in batch if t not in cache]\n",
    "\n",
    "        if not new_texts:\n",
    "            results.extend([cache[t] for t in batch])\n",
    "            continue\n",
    "\n",
    "        batch_prompt = \"\\n\".join([f\"{j+1}. {t}\" for j, t in enumerate(new_texts, start=1)])\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ë¬¸ì¥ë“¤ì˜ ê°ì •ì„ JSON ë°°ì—´ë¡œ ì •í™•íˆ ì¶œë ¥í•´.\n",
    "        ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì¤‘ í•˜ë‚˜ì˜ ê°ì •(sentiment)ê³¼ ì‹ ë¢°ë„(confidence, 0~1)ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n",
    "        [\n",
    "          {{\"id\":1, \"sentiment\":\"ë¶€ì •\", \"confidence\":0.93}},\n",
    "          {{\"id\":2, \"sentiment\":\"ì¤‘ë¦½\", \"confidence\":0.55}}\n",
    "        ]\n",
    "\n",
    "        ë¬¸ì¥:\n",
    "        {batch_prompt}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "            json_match = re.search(r\"\\[.*\\]\", output, re.S)\n",
    "\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"âš ï¸ JSON Decode Error â†’ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ëŒ€ì²´\")\n",
    "                    parsed = []\n",
    "            else:\n",
    "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸:\", output[:200])\n",
    "                parsed = []\n",
    "\n",
    "            batch_results = []\n",
    "            for j, t in enumerate(new_texts, start=1):\n",
    "                if j <= len(parsed):\n",
    "                    s = parsed[j-1].get(\"sentiment\", \"ì¤‘ë¦½\")\n",
    "                    c = parsed[j-1].get(\"confidence\", 0.5)\n",
    "                    batch_results.append({\"sentiment\": s, \"confidence\": c})\n",
    "                else:\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "\n",
    "            # ğŸ”’ ê¸¸ì´ ë¶ˆì¼ì¹˜ ìë™ ë³´ì •\n",
    "            if len(batch_results) != len(new_texts):\n",
    "                print(f\"âš ï¸ Batch ê¸¸ì´ ë¶ˆì¼ì¹˜: ì…ë ¥ {len(new_texts)}, ê²°ê³¼ {len(batch_results)} â†’ ìë™ë³´ì •\")\n",
    "                while len(batch_results) < len(new_texts):\n",
    "                    batch_results.append({\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0})\n",
    "                batch_results = batch_results[:len(new_texts)]\n",
    "\n",
    "            # âœ… ìºì‹œì— ì €ì¥\n",
    "            for t, r in zip(new_texts, batch_results):\n",
    "                cache[t] = r\n",
    "\n",
    "            results.extend([cache[t] for t in batch])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            results.extend([{\"sentiment\": \"ì¤‘ë¦½\", \"confidence\": 0.0} for _ in batch])\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ (íŒŒì¼ í™•ì¥ì ìë™ íŒë³„ + ê³µë°± ì œê±° + ì¸ì½”ë”© ì²˜ë¦¬)\n",
    "# ------------------------------------------------------------\n",
    "input_paths = [\n",
    "    r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\SKT_ë‰´ìŠ¤_20250401-20250531.csv\",\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for path in input_paths:\n",
    "    path = path.strip()\n",
    "    try:\n",
    "        if path.lower().endswith(\".csv\"):\n",
    "            df_temp = pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "        elif path.lower().endswith((\".xls\", \".xlsx\")):\n",
    "            df_temp = pd.read_excel(path, engine=\"openpyxl\")\n",
    "        else:\n",
    "            raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {path}\")\n",
    "        dfs.append(df_temp)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {path} â†’ {e}\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "if \"ë‰´ìŠ¤ì œëª©\" not in df.columns:\n",
    "    raise ValueError(\"âš ï¸ ì…ë ¥ íŒŒì¼ì— 'ë‰´ìŠ¤ì œëª©' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "df[\"ë‰´ìŠ¤ì œëª©\"] = df[\"ë‰´ìŠ¤ì œëª©\"].astype(str).str.strip().str[:300]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ GPT ê°ì •ë¶„ì„ ì‹¤í–‰\n",
    "# ------------------------------------------------------------\n",
    "results = gpt_batch_sentiment(df[\"ë‰´ìŠ¤ì œëª©\"].tolist(), batch_size=20)\n",
    "\n",
    "df[\"gpt_sentiment\"] = [r[\"sentiment\"] for r in results]\n",
    "df[\"gpt_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\speec\\OneDrive\\Desktop\\PoC_v2\\ê³µìœ í´ë”(ë”¥í…Œí¬)\\SKT_ë‰´ìŠ¤ê°ì •ë¶„ì„_GPT_labeled.xlsx\"\n",
    "df.to_excel(output_path, index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(f\"\\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ê²½ë¡œ:\\nğŸ“‚ {output_path}\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}